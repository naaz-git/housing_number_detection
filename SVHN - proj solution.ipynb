{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfIVI6MQiMzE"
   },
   "source": [
    "## Street View Housing Number Digit Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tensorflow\n",
    "import numpy as np\n",
    "# pip install matplotlib\n",
    "# pip install np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the SVHN dataset from the h5py file and understand the train/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uFAwwd53iMza"
   },
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (42000, 32, 32)\n",
      "y_train (42000,)\n",
      "X_test (18000, 32, 32)\n",
      "y_test (18000,)\n",
      "X_val (60000, 32, 32)\n",
      "y_val (60000,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('Autonomous_Vehicles_SVHN_single_grey1.h5','r')\n",
    "h5f.keys()\n",
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test = h5f['y_test'][:]\n",
    "X_val = h5f['X_val']\n",
    "y_val = h5f['y_val']\n",
    "print('X_train',X_train.shape)\n",
    "print('y_train',y_train.shape)\n",
    "print('X_test',X_test.shape)\n",
    "print('y_test',y_test.shape)\n",
    "print('X_val',X_val.shape)\n",
    "print('y_val',y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset size: 42k\n",
    "## Val dataset size: 60k\n",
    "## Test dataset size: 18k\n",
    "## Image size: 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val (8400, 32, 32)\n",
      "y_val (8400,)\n"
     ]
    }
   ],
   "source": [
    "X_val = h5f['X_val'][0:8400]\n",
    "y_val = h5f['y_val'][0:8400]\n",
    "print('X_val',X_val.shape)\n",
    "print('y_val',y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since validation dataset is huge, I am going to use 20% [60k*0.2] of the total validation set to reduce total time taken for validation during training process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape and normalize the train and test features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to 2D tensor: We need to feed a 2D tensor into the model and currently we have a 3D tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(8400, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(42000, 1024)\n",
    "print(X_train.shape)\n",
    "X_val = X_val.reshape(8400, 1024)\n",
    "print(X_val.shape)\n",
    "X_test = X_test.reshape(18000, 1024)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize few samples of training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image: [2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape(32, 32))\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize image pixels from 0:255 Range -> 0:1 Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000,)\n",
      "(8400,)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "# # normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255.\n",
    "X_val = X_val / 255.\n",
    "X_test = X_test /255.\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encode the labels for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_val = tensorflow.keras.utils.to_categorical(y_val, num_classes=10)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJ587e81iMzk"
   },
   "source": [
    "#### Define the model architecture using TensorFlow with a flatten layer followed by dense layers with activation as ReLu and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model with loss as categorical cross-entropy and adam optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeldef_train_and_test_loop(iterations, lr, Lambda, verb=True, graph = False):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "        \n",
    "    model = Sequential()\n",
    "    # Normalize the data\n",
    "    model.add(tensorflow.keras.layers.BatchNormalization())\n",
    "    # Hidden layers\n",
    "    model.add(tensorflow.keras.layers.Dense(hidden_nodes, activation='relu', name='Layer_1'))\n",
    "    model.add(tensorflow.keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
    "\n",
    "    # Dropout layer\n",
    "    model.add(tensorflow.keras.layers.Dropout(0.5))\n",
    "\n",
    "    # Hidden layers\n",
    "    model.add(tensorflow.keras.layers.Dense(60, activation='relu', name='Layer_3'))\n",
    "    model.add(tensorflow.keras.layers.Dense(30, activation='relu', name='Layer_4'))\n",
    "\n",
    "    # Dropout layer\n",
    "    model.add(tensorflow.keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "#     sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    if(graph == True):\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=iterations, batch_size=1000, verbose= 1,callbacks=[plot_losses])\n",
    "    else:\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    \n",
    "    #,callbacks=[plot_losses]\n",
    "    score = model.evaluate(X_train, y_train, verbose=0)\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('test_score',test_score)\n",
    "    \n",
    "    return model, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for printing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingPlot(tensorflow.keras.callbacks.Callback):\n",
    "    \n",
    "    # This function is called when the training begins\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Initialize the lists for holding the logs, losses and accuracies\n",
    "        self.losses = []\n",
    "        self.acc = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "    \n",
    "    # This function is called at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        # Append the logs, losses and accuracies to the lists\n",
    "        self.logs.append(logs)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "        # Before plotting ensure at least 2 epochs have passed\n",
    "        if len(self.losses) > 1:\n",
    "            \n",
    "            # Clear the previous plot\n",
    "            clear_output(wait=True)\n",
    "            N = np.arange(0, len(self.losses))\n",
    "            \n",
    "            # You can chose the style of your preference\n",
    "            # print(plt.style.available) to see the available options\n",
    "            plt.style.use(\"seaborn\")\n",
    "            \n",
    "            # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "            plt.figure()\n",
    "            plt.plot(N, self.losses, label = \"train_loss\")\n",
    "            plt.plot(N, self.acc, label = \"accuracy\")\n",
    "            plt.plot(N, self.val_losses, label = \"val_loss\")\n",
    "            plt.plot(N, self.val_acc, label = \"val_accuracy\")\n",
    "            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(epoch))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss/Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "plot_losses = TrainingPlot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 2.3174 - accuracy: 0.1312 - val_loss: 2.3091 - val_accuracy: 0.0658\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.0630 - accuracy: 0.2559 - val_loss: 2.1214 - val_accuracy: 0.5019\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.6672 - accuracy: 0.4256 - val_loss: 1.8173 - val_accuracy: 0.5958\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.4035 - accuracy: 0.5374 - val_loss: 1.4869 - val_accuracy: 0.6955\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.2630 - accuracy: 0.5955 - val_loss: 1.2611 - val_accuracy: 0.7481\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.1614 - accuracy: 0.6306 - val_loss: 1.1436 - val_accuracy: 0.7307\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.1041 - accuracy: 0.6549 - val_loss: 0.9826 - val_accuracy: 0.7751\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.0175 - accuracy: 0.6874 - val_loss: 0.8692 - val_accuracy: 0.7982\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9640 - accuracy: 0.7040 - val_loss: 0.8427 - val_accuracy: 0.7867\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9238 - accuracy: 0.7198 - val_loss: 0.7149 - val_accuracy: 0.8117\n",
      "test_score [0.758831552611457, 0.7759445]\n"
     ]
    }
   ],
   "source": [
    "model, bestscore = modeldef_train_and_test_loop(10, 0.1, 0.001, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo multiple                  4096      \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              multiple                  262400    \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              multiple                  25700     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "Layer_3 (Dense)              multiple                  6060      \n",
      "_________________________________________________________________\n",
      "Layer_4 (Dense)              multiple                  1830      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  310       \n",
      "=================================================================\n",
      "Total params: 300,396\n",
      "Trainable params: 298,348\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best hyperparameter values for learning rate and Best Lambda for L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 2.3132 - accuracy: 0.1308 - val_loss: 2.2993 - val_accuracy: 0.0489\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 2.1073 - accuracy: 0.2211 - val_loss: 2.1526 - val_accuracy: 0.3792\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.8209 - accuracy: 0.3471 - val_loss: 1.9431 - val_accuracy: 0.4056\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.5663 - accuracy: 0.4585 - val_loss: 1.6629 - val_accuracy: 0.6086\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 1.3949 - accuracy: 0.5324 - val_loss: 1.4102 - val_accuracy: 0.6561\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 1.2705 - accuracy: 0.5824 - val_loss: 1.2281 - val_accuracy: 0.6874\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.1662 - accuracy: 0.6228 - val_loss: 1.0095 - val_accuracy: 0.7468\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.0996 - accuracy: 0.6490 - val_loss: 0.9450 - val_accuracy: 0.7626\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 1.0359 - accuracy: 0.6720 - val_loss: 0.8015 - val_accuracy: 0.7963\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9876 - accuracy: 0.6884 - val_loss: 0.7824 - val_accuracy: 0.7844\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.9393 - accuracy: 0.7027 - val_loss: 0.7085 - val_accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.8835 - accuracy: 0.7252 - val_loss: 0.6800 - val_accuracy: 0.8157\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8568 - accuracy: 0.7323 - val_loss: 0.6149 - val_accuracy: 0.8371\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8148 - accuracy: 0.7490 - val_loss: 0.5732 - val_accuracy: 0.8480\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7945 - accuracy: 0.7551 - val_loss: 0.6025 - val_accuracy: 0.8398\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7734 - accuracy: 0.7624 - val_loss: 0.5864 - val_accuracy: 0.8464\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7542 - accuracy: 0.7690 - val_loss: 0.5257 - val_accuracy: 0.8565\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7254 - accuracy: 0.7771 - val_loss: 0.5491 - val_accuracy: 0.8473\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.7014 - accuracy: 0.7870 - val_loss: 0.5902 - val_accuracy: 0.8292\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6914 - accuracy: 0.7881 - val_loss: 0.5683 - val_accuracy: 0.8399\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6835 - accuracy: 0.7924 - val_loss: 0.5308 - val_accuracy: 0.8482\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6639 - accuracy: 0.7984 - val_loss: 0.5728 - val_accuracy: 0.8367\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6372 - accuracy: 0.8070 - val_loss: 0.5383 - val_accuracy: 0.8500\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6365 - accuracy: 0.8079 - val_loss: 0.4878 - val_accuracy: 0.8665\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6142 - accuracy: 0.8140 - val_loss: 0.5010 - val_accuracy: 0.8657\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6025 - accuracy: 0.8170 - val_loss: 0.5070 - val_accuracy: 0.8604\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6030 - accuracy: 0.8171 - val_loss: 0.5002 - val_accuracy: 0.8627\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5755 - accuracy: 0.8259 - val_loss: 0.4906 - val_accuracy: 0.8620\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 0.5777 - accuracy: 0.8240 - val_loss: 0.4680 - val_accuracy: 0.8719\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 2s 45us/sample - loss: 0.5601 - accuracy: 0.8318 - val_loss: 0.4527 - val_accuracy: 0.8775\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5560 - accuracy: 0.8305 - val_loss: 0.4735 - val_accuracy: 0.8693\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5410 - accuracy: 0.8361 - val_loss: 0.4529 - val_accuracy: 0.8777\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5173 - accuracy: 0.8433 - val_loss: 0.4601 - val_accuracy: 0.8730\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5229 - accuracy: 0.8425 - val_loss: 0.4408 - val_accuracy: 0.8788\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5110 - accuracy: 0.8477 - val_loss: 0.4340 - val_accuracy: 0.8810\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5045 - accuracy: 0.8475 - val_loss: 0.4330 - val_accuracy: 0.8827\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4962 - accuracy: 0.8520 - val_loss: 0.4266 - val_accuracy: 0.8830\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4786 - accuracy: 0.8551 - val_loss: 0.3964 - val_accuracy: 0.8926\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4832 - accuracy: 0.8554 - val_loss: 0.4292 - val_accuracy: 0.8849\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4814 - accuracy: 0.8550 - val_loss: 0.3637 - val_accuracy: 0.9036\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4871 - accuracy: 0.8534 - val_loss: 0.4352 - val_accuracy: 0.8846\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4617 - accuracy: 0.8606 - val_loss: 0.3846 - val_accuracy: 0.9001\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.4556 - accuracy: 0.8630 - val_loss: 0.3881 - val_accuracy: 0.8945\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 2s 36us/sample - loss: 0.4564 - accuracy: 0.8622 - val_loss: 0.3877 - val_accuracy: 0.8982\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4727 - accuracy: 0.8577 - val_loss: 0.3909 - val_accuracy: 0.8974\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4455 - accuracy: 0.8648 - val_loss: 0.3748 - val_accuracy: 0.8998\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4370 - accuracy: 0.8683 - val_loss: 0.4140 - val_accuracy: 0.8876\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4303 - accuracy: 0.8715 - val_loss: 0.3878 - val_accuracy: 0.8965\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4342 - accuracy: 0.8693 - val_loss: 0.3917 - val_accuracy: 0.8992\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4258 - accuracy: 0.8707 - val_loss: 0.4210 - val_accuracy: 0.8831\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4234 - accuracy: 0.8728 - val_loss: 0.3670 - val_accuracy: 0.9008\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.4158 - accuracy: 0.8752 - val_loss: 0.3742 - val_accuracy: 0.9026\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.4132 - accuracy: 0.8762 - val_loss: 0.4355 - val_accuracy: 0.8848\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4205 - accuracy: 0.8729 - val_loss: 0.3811 - val_accuracy: 0.8979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4025 - accuracy: 0.8790 - val_loss: 0.3663 - val_accuracy: 0.9035\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.4089 - accuracy: 0.8765 - val_loss: 0.3587 - val_accuracy: 0.9055\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.4000 - accuracy: 0.8807 - val_loss: 0.3668 - val_accuracy: 0.9045\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3828 - accuracy: 0.8830 - val_loss: 0.3560 - val_accuracy: 0.9044\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3957 - accuracy: 0.8805 - val_loss: 0.3627 - val_accuracy: 0.9042\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3882 - accuracy: 0.8837 - val_loss: 0.3632 - val_accuracy: 0.9018\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3968 - accuracy: 0.8795 - val_loss: 0.3603 - val_accuracy: 0.9065\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3777 - accuracy: 0.8860 - val_loss: 0.3605 - val_accuracy: 0.9082\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3871 - accuracy: 0.8823 - val_loss: 0.3583 - val_accuracy: 0.9069\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3746 - accuracy: 0.8871 - val_loss: 0.3631 - val_accuracy: 0.9074\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3833 - accuracy: 0.8854 - val_loss: 0.3731 - val_accuracy: 0.8993\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.3633 - accuracy: 0.8898 - val_loss: 0.3632 - val_accuracy: 0.9057\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.3574 - accuracy: 0.8919 - val_loss: 0.3701 - val_accuracy: 0.9057\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3744 - accuracy: 0.8863 - val_loss: 0.3387 - val_accuracy: 0.9164\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3597 - accuracy: 0.8919 - val_loss: 0.3488 - val_accuracy: 0.9106\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3619 - accuracy: 0.8901 - val_loss: 0.3443 - val_accuracy: 0.9146\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3687 - accuracy: 0.8896 - val_loss: 0.3208 - val_accuracy: 0.9174\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3557 - accuracy: 0.8933 - val_loss: 0.3425 - val_accuracy: 0.9139\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3508 - accuracy: 0.8938 - val_loss: 0.3654 - val_accuracy: 0.9065\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3507 - accuracy: 0.8941 - val_loss: 0.3221 - val_accuracy: 0.9198\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3383 - accuracy: 0.8968 - val_loss: 0.3713 - val_accuracy: 0.9050\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3406 - accuracy: 0.8952 - val_loss: 0.3412 - val_accuracy: 0.9126\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3329 - accuracy: 0.8990 - val_loss: 0.3360 - val_accuracy: 0.9131\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3396 - accuracy: 0.8973 - val_loss: 0.3687 - val_accuracy: 0.9054\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3428 - accuracy: 0.8968 - val_loss: 0.2980 - val_accuracy: 0.9269\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.3327 - accuracy: 0.8990 - val_loss: 0.3087 - val_accuracy: 0.9233\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.3270 - accuracy: 0.9005 - val_loss: 0.3445 - val_accuracy: 0.9110\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3274 - accuracy: 0.9012 - val_loss: 0.3150 - val_accuracy: 0.9205\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3271 - accuracy: 0.8993 - val_loss: 0.3113 - val_accuracy: 0.9258\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3223 - accuracy: 0.9033 - val_loss: 0.3210 - val_accuracy: 0.9230\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3213 - accuracy: 0.9022 - val_loss: 0.3398 - val_accuracy: 0.9190\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.3158 - accuracy: 0.9036 - val_loss: 0.3446 - val_accuracy: 0.9175\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.3240 - accuracy: 0.9027 - val_loss: 0.3167 - val_accuracy: 0.9243\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3137 - accuracy: 0.9063 - val_loss: 0.3393 - val_accuracy: 0.9146\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3221 - accuracy: 0.9040 - val_loss: 0.3419 - val_accuracy: 0.9169\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3123 - accuracy: 0.9046 - val_loss: 0.3183 - val_accuracy: 0.9212\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3198 - accuracy: 0.9033 - val_loss: 0.3435 - val_accuracy: 0.9150\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.3124 - accuracy: 0.9047 - val_loss: 0.3127 - val_accuracy: 0.9256\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2966 - accuracy: 0.9106 - val_loss: 0.3167 - val_accuracy: 0.9276\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2953 - accuracy: 0.9099 - val_loss: 0.3301 - val_accuracy: 0.9240\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3180 - accuracy: 0.9037 - val_loss: 0.3745 - val_accuracy: 0.9108\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3053 - accuracy: 0.9067 - val_loss: 0.3234 - val_accuracy: 0.9225\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2990 - accuracy: 0.9107 - val_loss: 0.3190 - val_accuracy: 0.9246\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3048 - accuracy: 0.9090 - val_loss: 0.3397 - val_accuracy: 0.9150\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.3047 - accuracy: 0.9075 - val_loss: 0.2842 - val_accuracy: 0.9340\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.3044 - accuracy: 0.9084 - val_loss: 0.3468 - val_accuracy: 0.9154\n",
      "test_score [0.5753591249949402, 0.8602778]\n",
      "Try 1/100: Best_val_acc: [0.5753591249949402, 0.8602778], lr: 5.294506661243704e-05, Lambda: 1.0600552954866772e-07\n",
      "\n",
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 2.2797 - accuracy: 0.1546 - val_loss: 2.2790 - val_accuracy: 0.2893\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.9432 - accuracy: 0.3049 - val_loss: 1.9993 - val_accuracy: 0.5964\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.6170 - accuracy: 0.4384 - val_loss: 1.7741 - val_accuracy: 0.5981\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.4242 - accuracy: 0.5241 - val_loss: 1.4987 - val_accuracy: 0.7018\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.2875 - accuracy: 0.5804 - val_loss: 1.3431 - val_accuracy: 0.6960\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.1829 - accuracy: 0.6216 - val_loss: 1.1023 - val_accuracy: 0.7555\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.1042 - accuracy: 0.6498 - val_loss: 0.9649 - val_accuracy: 0.7735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 1.0337 - accuracy: 0.6756 - val_loss: 0.8372 - val_accuracy: 0.8087\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 0.9822 - accuracy: 0.6944 - val_loss: 0.8454 - val_accuracy: 0.7774\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.9244 - accuracy: 0.7168 - val_loss: 0.7102 - val_accuracy: 0.8133\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8918 - accuracy: 0.7247 - val_loss: 0.6849 - val_accuracy: 0.8186\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8549 - accuracy: 0.7388 - val_loss: 0.6635 - val_accuracy: 0.8264\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8129 - accuracy: 0.7508 - val_loss: 0.6328 - val_accuracy: 0.8258\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7947 - accuracy: 0.7564 - val_loss: 0.6421 - val_accuracy: 0.8289\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7580 - accuracy: 0.7679 - val_loss: 0.5931 - val_accuracy: 0.8396\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.7365 - accuracy: 0.7764 - val_loss: 0.5692 - val_accuracy: 0.8511\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7151 - accuracy: 0.7862 - val_loss: 0.5652 - val_accuracy: 0.8467\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7117 - accuracy: 0.7856 - val_loss: 0.5467 - val_accuracy: 0.8515\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6750 - accuracy: 0.7978 - val_loss: 0.5504 - val_accuracy: 0.8506\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6576 - accuracy: 0.8026 - val_loss: 0.5380 - val_accuracy: 0.8513\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6479 - accuracy: 0.8057 - val_loss: 0.5034 - val_accuracy: 0.8585\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6340 - accuracy: 0.8101 - val_loss: 0.4944 - val_accuracy: 0.8675\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.6184 - accuracy: 0.8148 - val_loss: 0.5121 - val_accuracy: 0.8630\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 2s 41us/sample - loss: 0.6177 - accuracy: 0.8149 - val_loss: 0.4476 - val_accuracy: 0.8792\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 2s 36us/sample - loss: 0.5872 - accuracy: 0.8253 - val_loss: 0.5184 - val_accuracy: 0.8608\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.5848 - accuracy: 0.8254 - val_loss: 0.4613 - val_accuracy: 0.8765\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5785 - accuracy: 0.8282 - val_loss: 0.5226 - val_accuracy: 0.8546\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5695 - accuracy: 0.8305 - val_loss: 0.4603 - val_accuracy: 0.8775\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5501 - accuracy: 0.8382 - val_loss: 0.4440 - val_accuracy: 0.8783\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5369 - accuracy: 0.8397 - val_loss: 0.5048 - val_accuracy: 0.8636\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5410 - accuracy: 0.8377 - val_loss: 0.4309 - val_accuracy: 0.8849: 0.5378 - accuracy\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.5203 - accuracy: 0.8449 - val_loss: 0.4553 - val_accuracy: 0.8771\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.5236 - accuracy: 0.8415 - val_loss: 0.4451 - val_accuracy: 0.8795\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5135 - accuracy: 0.8468 - val_loss: 0.4307 - val_accuracy: 0.8826\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5131 - accuracy: 0.8487 - val_loss: 0.4032 - val_accuracy: 0.8958\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.4904 - accuracy: 0.8554 - val_loss: 0.4375 - val_accuracy: 0.8837\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.4819 - accuracy: 0.8568 - val_loss: 0.4381 - val_accuracy: 0.8827\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.4772 - accuracy: 0.8596 - val_loss: 0.4039 - val_accuracy: 0.8917\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 3s 61us/sample - loss: 0.4836 - accuracy: 0.8565 - val_loss: 0.4268 - val_accuracy: 0.8840\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.4714 - accuracy: 0.8613 - val_loss: 0.4207 - val_accuracy: 0.8886\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.4686 - accuracy: 0.8615 - val_loss: 0.3910 - val_accuracy: 0.8956\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.4613 - accuracy: 0.8624 - val_loss: 0.4187 - val_accuracy: 0.8862\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.4548 - accuracy: 0.8678 - val_loss: 0.3654 - val_accuracy: 0.9024\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.4386 - accuracy: 0.8705 - val_loss: 0.3809 - val_accuracy: 0.9010\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.4557 - accuracy: 0.8646 - val_loss: 0.3926 - val_accuracy: 0.8935\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.4550 - accuracy: 0.8645 - val_loss: 0.4258 - val_accuracy: 0.8875\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.4341 - accuracy: 0.8705 - val_loss: 0.3822 - val_accuracy: 0.9015\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.4296 - accuracy: 0.8724 - val_loss: 0.4227 - val_accuracy: 0.8888\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.4304 - accuracy: 0.8736 - val_loss: 0.3945 - val_accuracy: 0.8980\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.4181 - accuracy: 0.8766 - val_loss: 0.3690 - val_accuracy: 0.9038\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.4159 - accuracy: 0.8758 - val_loss: 0.4086 - val_accuracy: 0.8938\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.4086 - accuracy: 0.8781 - val_loss: 0.3774 - val_accuracy: 0.9014\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.4108 - accuracy: 0.8780 - val_loss: 0.3738 - val_accuracy: 0.9033\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.4155 - accuracy: 0.8764 - val_loss: 0.3837 - val_accuracy: 0.9007\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.4158 - accuracy: 0.8775 - val_loss: 0.4005 - val_accuracy: 0.8946\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 2s 37us/sample - loss: 0.3979 - accuracy: 0.8817 - val_loss: 0.4104 - val_accuracy: 0.8862\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.4073 - accuracy: 0.8809 - val_loss: 0.3414 - val_accuracy: 0.9145\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3911 - accuracy: 0.8839 - val_loss: 0.3532 - val_accuracy: 0.9098\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3935 - accuracy: 0.8830 - val_loss: 0.3631 - val_accuracy: 0.9071\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3841 - accuracy: 0.8853 - val_loss: 0.4383 - val_accuracy: 0.8865\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3931 - accuracy: 0.8826 - val_loss: 0.3725 - val_accuracy: 0.9065\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3927 - accuracy: 0.8839 - val_loss: 0.3564 - val_accuracy: 0.9101\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3843 - accuracy: 0.8878 - val_loss: 0.3310 - val_accuracy: 0.9179\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3817 - accuracy: 0.8876 - val_loss: 0.3719 - val_accuracy: 0.9043\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3795 - accuracy: 0.8862 - val_loss: 0.3855 - val_accuracy: 0.9071\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3642 - accuracy: 0.8905 - val_loss: 0.3368 - val_accuracy: 0.9154\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3698 - accuracy: 0.8908 - val_loss: 0.3453 - val_accuracy: 0.9123\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3761 - accuracy: 0.8879 - val_loss: 0.3599 - val_accuracy: 0.9092\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3820 - accuracy: 0.8860 - val_loss: 0.3446 - val_accuracy: 0.9155\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.3548 - accuracy: 0.8967 - val_loss: 0.3592 - val_accuracy: 0.9121\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3577 - accuracy: 0.8940 - val_loss: 0.3644 - val_accuracy: 0.9080\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3413 - accuracy: 0.8991 - val_loss: 0.3243 - val_accuracy: 0.9193\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3486 - accuracy: 0.8969 - val_loss: 0.3374 - val_accuracy: 0.9188\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.3576 - accuracy: 0.8936 - val_loss: 0.3597 - val_accuracy: 0.9115\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3378 - accuracy: 0.9004 - val_loss: 0.3394 - val_accuracy: 0.9161\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3429 - accuracy: 0.8967 - val_loss: 0.3392 - val_accuracy: 0.9181\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3389 - accuracy: 0.9000 - val_loss: 0.3398 - val_accuracy: 0.9164\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3346 - accuracy: 0.9006 - val_loss: 0.3349 - val_accuracy: 0.9188\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3322 - accuracy: 0.9009 - val_loss: 0.3262 - val_accuracy: 0.9218\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3369 - accuracy: 0.9002 - val_loss: 0.3286 - val_accuracy: 0.9185\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3377 - accuracy: 0.9003 - val_loss: 0.3077 - val_accuracy: 0.9244\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3374 - accuracy: 0.8991 - val_loss: 0.3299 - val_accuracy: 0.9187\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3209 - accuracy: 0.9048 - val_loss: 0.3886 - val_accuracy: 0.9031\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.3309 - accuracy: 0.9025 - val_loss: 0.3595 - val_accuracy: 0.9090\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3313 - accuracy: 0.9015 - val_loss: 0.3626 - val_accuracy: 0.9101\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3280 - accuracy: 0.9027 - val_loss: 0.3059 - val_accuracy: 0.9268\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3247 - accuracy: 0.9039 - val_loss: 0.3193 - val_accuracy: 0.9227\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3212 - accuracy: 0.9060 - val_loss: 0.3317 - val_accuracy: 0.9183\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3290 - accuracy: 0.9028 - val_loss: 0.2924 - val_accuracy: 0.9308\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.3146 - accuracy: 0.9062 - val_loss: 0.3322 - val_accuracy: 0.9187\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.3250 - accuracy: 0.9043 - val_loss: 0.3435 - val_accuracy: 0.9149\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3089 - accuracy: 0.9077 - val_loss: 0.3168 - val_accuracy: 0.9231\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3057 - accuracy: 0.9104 - val_loss: 0.2939 - val_accuracy: 0.9306\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3045 - accuracy: 0.9107 - val_loss: 0.3439 - val_accuracy: 0.9177\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.2989 - accuracy: 0.9108 - val_loss: 0.3299 - val_accuracy: 0.9231\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3007 - accuracy: 0.9097 - val_loss: 0.3114 - val_accuracy: 0.9250\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3069 - accuracy: 0.9086 - val_loss: 0.3304 - val_accuracy: 0.9230\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3107 - accuracy: 0.9084 - val_loss: 0.3538 - val_accuracy: 0.9136\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2973 - accuracy: 0.9115 - val_loss: 0.3190 - val_accuracy: 0.9220\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2959 - accuracy: 0.9117 - val_loss: 0.3377 - val_accuracy: 0.9193\n",
      "test_score [0.5728719647924105, 0.8595]\n",
      "Try 2/100: Best_val_acc: [0.5728719647924105, 0.8595], lr: 0.42983215187293944, Lambda: 0.0002272219095809123\n",
      "\n",
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 2.3080 - accuracy: 0.1257 - val_loss: 2.2707 - val_accuracy: 0.3895\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 2.0818 - accuracy: 0.2331 - val_loss: 2.2033 - val_accuracy: 0.3382\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.7637 - accuracy: 0.3682 - val_loss: 1.8573 - val_accuracy: 0.6402\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.4899 - accuracy: 0.4909 - val_loss: 1.5651 - val_accuracy: 0.6740\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 1.3092 - accuracy: 0.5699 - val_loss: 1.3437 - val_accuracy: 0.7112\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 1.1911 - accuracy: 0.6160 - val_loss: 1.1055 - val_accuracy: 0.7462\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 36us/sample - loss: 1.0944 - accuracy: 0.6514 - val_loss: 0.9449 - val_accuracy: 0.7777\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0325 - accuracy: 0.6740 - val_loss: 0.8380 - val_accuracy: 0.7976\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9731 - accuracy: 0.6950 - val_loss: 0.7704 - val_accuracy: 0.8056\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9232 - accuracy: 0.7125 - val_loss: 0.7303 - val_accuracy: 0.8064\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8869 - accuracy: 0.7234 - val_loss: 0.7326 - val_accuracy: 0.8040\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8462 - accuracy: 0.7393 - val_loss: 0.7058 - val_accuracy: 0.8042\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.8333 - accuracy: 0.7457 - val_loss: 0.6423 - val_accuracy: 0.8205\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.8051 - accuracy: 0.7519 - val_loss: 0.5819 - val_accuracy: 0.8451\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7668 - accuracy: 0.7653 - val_loss: 0.6257 - val_accuracy: 0.8340\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7578 - accuracy: 0.7676 - val_loss: 0.5885 - val_accuracy: 0.8395\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7188 - accuracy: 0.7791 - val_loss: 0.5203 - val_accuracy: 0.8640\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7028 - accuracy: 0.7859 - val_loss: 0.5794 - val_accuracy: 0.8395\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6734 - accuracy: 0.7962 - val_loss: 0.5587 - val_accuracy: 0.8471\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6664 - accuracy: 0.7969 - val_loss: 0.5535 - val_accuracy: 0.8507\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6463 - accuracy: 0.8042 - val_loss: 0.5327 - val_accuracy: 0.8565\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 0.6511 - accuracy: 0.8017 - val_loss: 0.5706 - val_accuracy: 0.8427\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.6264 - accuracy: 0.8092 - val_loss: 0.4922 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6040 - accuracy: 0.8182 - val_loss: 0.4799 - val_accuracy: 0.8696\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.5995 - accuracy: 0.8185 - val_loss: 0.4668 - val_accuracy: 0.8768\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.5908 - accuracy: 0.8230 - val_loss: 0.5008 - val_accuracy: 0.8638\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5856 - accuracy: 0.8240 - val_loss: 0.4712 - val_accuracy: 0.8761\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5576 - accuracy: 0.8325 - val_loss: 0.4582 - val_accuracy: 0.8763\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5518 - accuracy: 0.8326 - val_loss: 0.4863 - val_accuracy: 0.8635\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5496 - accuracy: 0.8336 - val_loss: 0.4605 - val_accuracy: 0.8723\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5331 - accuracy: 0.8401 - val_loss: 0.4484 - val_accuracy: 0.8786\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5369 - accuracy: 0.8397 - val_loss: 0.4214 - val_accuracy: 0.8881\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5220 - accuracy: 0.8427 - val_loss: 0.4335 - val_accuracy: 0.8854\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5143 - accuracy: 0.8467 - val_loss: 0.4386 - val_accuracy: 0.8807\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5057 - accuracy: 0.8488 - val_loss: 0.4320 - val_accuracy: 0.8835\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4920 - accuracy: 0.8507 - val_loss: 0.4066 - val_accuracy: 0.8910\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.4889 - accuracy: 0.8527 - val_loss: 0.4240 - val_accuracy: 0.8867\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4853 - accuracy: 0.8528 - val_loss: 0.4805 - val_accuracy: 0.8690\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4744 - accuracy: 0.8583 - val_loss: 0.4448 - val_accuracy: 0.8814\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4798 - accuracy: 0.8559 - val_loss: 0.4181 - val_accuracy: 0.8885\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4616 - accuracy: 0.8631 - val_loss: 0.3836 - val_accuracy: 0.9006\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.4658 - accuracy: 0.8609 - val_loss: 0.4305 - val_accuracy: 0.8845\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 2s 45us/sample - loss: 0.4495 - accuracy: 0.8630 - val_loss: 0.3973 - val_accuracy: 0.8949\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4482 - accuracy: 0.8672 - val_loss: 0.3674 - val_accuracy: 0.9048\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4494 - accuracy: 0.8657 - val_loss: 0.3965 - val_accuracy: 0.8948\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4441 - accuracy: 0.8682 - val_loss: 0.3916 - val_accuracy: 0.8980\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4332 - accuracy: 0.8712 - val_loss: 0.3795 - val_accuracy: 0.9018\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.4387 - accuracy: 0.8678 - val_loss: 0.4058 - val_accuracy: 0.8915\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4280 - accuracy: 0.8696 - val_loss: 0.4384 - val_accuracy: 0.8840\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4205 - accuracy: 0.8742 - val_loss: 0.3462 - val_accuracy: 0.9137\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4185 - accuracy: 0.8735 - val_loss: 0.3985 - val_accuracy: 0.8952\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4320 - accuracy: 0.8709 - val_loss: 0.3985 - val_accuracy: 0.8973\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4065 - accuracy: 0.8783 - val_loss: 0.3530 - val_accuracy: 0.9093\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.4094 - accuracy: 0.8793 - val_loss: 0.3586 - val_accuracy: 0.9052\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.4145 - accuracy: 0.8745 - val_loss: 0.3815 - val_accuracy: 0.9040\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4017 - accuracy: 0.8790 - val_loss: 0.4004 - val_accuracy: 0.8954\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.4006 - accuracy: 0.8795 - val_loss: 0.3806 - val_accuracy: 0.9048\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3957 - accuracy: 0.8832 - val_loss: 0.3662 - val_accuracy: 0.9104\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.3979 - accuracy: 0.8795 - val_loss: 0.4039 - val_accuracy: 0.8990\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3984 - accuracy: 0.8810 - val_loss: 0.3600 - val_accuracy: 0.9105\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3834 - accuracy: 0.8856 - val_loss: 0.3971 - val_accuracy: 0.8927\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3835 - accuracy: 0.8844 - val_loss: 0.3734 - val_accuracy: 0.9046\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3724 - accuracy: 0.8886 - val_loss: 0.3669 - val_accuracy: 0.9094\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3666 - accuracy: 0.8902 - val_loss: 0.3647 - val_accuracy: 0.9067\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3776 - accuracy: 0.8878 - val_loss: 0.3394 - val_accuracy: 0.9136\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.3727 - accuracy: 0.8881 - val_loss: 0.3566 - val_accuracy: 0.9089\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 0.3663 - accuracy: 0.8901 - val_loss: 0.3533 - val_accuracy: 0.9124\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3605 - accuracy: 0.8908 - val_loss: 0.3727 - val_accuracy: 0.9052\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3637 - accuracy: 0.8896 - val_loss: 0.3725 - val_accuracy: 0.9026\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3687 - accuracy: 0.8905 - val_loss: 0.3365 - val_accuracy: 0.9151\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3506 - accuracy: 0.8946 - val_loss: 0.3634 - val_accuracy: 0.9087\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3444 - accuracy: 0.8951 - val_loss: 0.3752 - val_accuracy: 0.9032\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 0.3611 - accuracy: 0.8914 - val_loss: 0.3264 - val_accuracy: 0.9189\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.89 - 2s 47us/sample - loss: 0.3398 - accuracy: 0.8990 - val_loss: 0.4006 - val_accuracy: 0.8965\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3475 - accuracy: 0.8961 - val_loss: 0.3411 - val_accuracy: 0.9132\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3322 - accuracy: 0.8992 - val_loss: 0.3301 - val_accuracy: 0.9179\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3507 - accuracy: 0.8949 - val_loss: 0.3532 - val_accuracy: 0.9115\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3385 - accuracy: 0.8967 - val_loss: 0.3733 - val_accuracy: 0.9045\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3254 - accuracy: 0.9031 - val_loss: 0.3100 - val_accuracy: 0.9264\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3275 - accuracy: 0.9005 - val_loss: 0.3523 - val_accuracy: 0.9127\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3388 - accuracy: 0.8980 - val_loss: 0.3190 - val_accuracy: 0.9224\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 2s 41us/sample - loss: 0.3220 - accuracy: 0.9015 - val_loss: 0.3434 - val_accuracy: 0.9139\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.3324 - accuracy: 0.9014 - val_loss: 0.3354 - val_accuracy: 0.9168\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3213 - accuracy: 0.9020 - val_loss: 0.3323 - val_accuracy: 0.9190\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3220 - accuracy: 0.9022 - val_loss: 0.3865 - val_accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 2s 38us/sample - loss: 0.3167 - accuracy: 0.9045 - val_loss: 0.3720 - val_accuracy: 0.9062\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.3348 - accuracy: 0.8982 - val_loss: 0.3066 - val_accuracy: 0.9251\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3350 - accuracy: 0.8980 - val_loss: 0.3510 - val_accuracy: 0.9085\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3192 - accuracy: 0.9036 - val_loss: 0.3492 - val_accuracy: 0.9148\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3135 - accuracy: 0.9060 - val_loss: 0.3280 - val_accuracy: 0.9196\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3065 - accuracy: 0.9082 - val_loss: 0.3513 - val_accuracy: 0.9139\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3113 - accuracy: 0.9058 - val_loss: 0.3359 - val_accuracy: 0.9205\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3114 - accuracy: 0.9062 - val_loss: 0.3525 - val_accuracy: 0.9129\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3202 - accuracy: 0.9030 - val_loss: 0.3386 - val_accuracy: 0.9199\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3108 - accuracy: 0.9064 - val_loss: 0.3372 - val_accuracy: 0.9242\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3135 - accuracy: 0.9050 - val_loss: 0.3425 - val_accuracy: 0.9182\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.3001 - accuracy: 0.9088 - val_loss: 0.3165 - val_accuracy: 0.9249 accuracy: \n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.3083 - accuracy: 0.9066 - val_loss: 0.3184 - val_accuracy: 0.9243\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3012 - accuracy: 0.9082 - val_loss: 0.3457 - val_accuracy: 0.9148\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3054 - accuracy: 0.9069 - val_loss: 0.2970 - val_accuracy: 0.9315\n",
      "test_score [0.5688414531416364, 0.85966665]\n",
      "Try 3/100: Best_val_acc: [0.5688414531416364, 0.85966665], lr: 0.00025721786244136926, Lambda: 8.521873717556332e-07\n",
      "\n",
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 2.2940 - accuracy: 0.1333 - val_loss: 2.2994 - val_accuracy: 0.1485\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.0423 - accuracy: 0.2439 - val_loss: 2.1160 - val_accuracy: 0.3901\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.7172 - accuracy: 0.3854 - val_loss: 1.7741 - val_accuracy: 0.6600\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.4892 - accuracy: 0.4918 - val_loss: 1.5425 - val_accuracy: 0.6577\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 1.3007 - accuracy: 0.5683 - val_loss: 1.2569 - val_accuracy: 0.7174\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 2s 38us/sample - loss: 1.1849 - accuracy: 0.6164 - val_loss: 1.0607 - val_accuracy: 0.7745\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0956 - accuracy: 0.6504 - val_loss: 0.9170 - val_accuracy: 0.7806\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.0128 - accuracy: 0.6789 - val_loss: 0.8167 - val_accuracy: 0.7894\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9595 - accuracy: 0.6965 - val_loss: 0.7006 - val_accuracy: 0.8218\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9130 - accuracy: 0.7150 - val_loss: 0.6584 - val_accuracy: 0.8264\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8754 - accuracy: 0.7279 - val_loss: 0.7164 - val_accuracy: 0.8076\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8319 - accuracy: 0.7440 - val_loss: 0.6016 - val_accuracy: 0.8362\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8120 - accuracy: 0.7486 - val_loss: 0.6123 - val_accuracy: 0.8269\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.7769 - accuracy: 0.7613 - val_loss: 0.5992 - val_accuracy: 0.8338\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 0.7517 - accuracy: 0.7688 - val_loss: 0.5810 - val_accuracy: 0.8413\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.7300 - accuracy: 0.7772 - val_loss: 0.5583 - val_accuracy: 0.8427\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.7189 - accuracy: 0.7829 - val_loss: 0.6129 - val_accuracy: 0.8308- ETA: 1s - loss: 0\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6916 - accuracy: 0.7908 - val_loss: 0.5465 - val_accuracy: 0.8494\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6722 - accuracy: 0.7964 - val_loss: 0.5368 - val_accuracy: 0.8467\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6691 - accuracy: 0.7962 - val_loss: 0.5514 - val_accuracy: 0.8450\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6415 - accuracy: 0.8056 - val_loss: 0.5239 - val_accuracy: 0.8521\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 2s 41us/sample - loss: 0.6262 - accuracy: 0.8099 - val_loss: 0.4911 - val_accuracy: 0.8643\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.6180 - accuracy: 0.8134 - val_loss: 0.4921 - val_accuracy: 0.8646\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5994 - accuracy: 0.8192 - val_loss: 0.4692 - val_accuracy: 0.8707\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5829 - accuracy: 0.8230 - val_loss: 0.4854 - val_accuracy: 0.8650\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5852 - accuracy: 0.8227 - val_loss: 0.4585 - val_accuracy: 0.8752\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5674 - accuracy: 0.8295 - val_loss: 0.4619 - val_accuracy: 0.8748\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5505 - accuracy: 0.8351 - val_loss: 0.4295 - val_accuracy: 0.8845\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5466 - accuracy: 0.8350 - val_loss: 0.4418 - val_accuracy: 0.8800\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.5369 - accuracy: 0.8377 - val_loss: 0.4623 - val_accuracy: 0.8765\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5327 - accuracy: 0.8374 - val_loss: 0.4581 - val_accuracy: 0.8729\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5223 - accuracy: 0.8418 - val_loss: 0.4307 - val_accuracy: 0.8851\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5149 - accuracy: 0.8430 - val_loss: 0.4231 - val_accuracy: 0.8879\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5106 - accuracy: 0.8466 - val_loss: 0.4477 - val_accuracy: 0.8808\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 0.5068 - accuracy: 0.8470 - val_loss: 0.4764 - val_accuracy: 0.8712\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 0.5003 - accuracy: 0.8482 - val_loss: 0.4027 - val_accuracy: 0.8939\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4922 - accuracy: 0.8511 - val_loss: 0.4212 - val_accuracy: 0.8870\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4873 - accuracy: 0.8544 - val_loss: 0.3984 - val_accuracy: 0.8951\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 0.4715 - accuracy: 0.8568 - val_loss: 0.4041 - val_accuracy: 0.8905\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.4672 - accuracy: 0.8585 - val_loss: 0.4372 - val_accuracy: 0.8863\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4712 - accuracy: 0.8575 - val_loss: 0.4009 - val_accuracy: 0.8942\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4615 - accuracy: 0.8605 - val_loss: 0.3787 - val_accuracy: 0.8995\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4534 - accuracy: 0.8626 - val_loss: 0.3721 - val_accuracy: 0.9037\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4426 - accuracy: 0.8667 - val_loss: 0.3939 - val_accuracy: 0.8964\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4372 - accuracy: 0.8701 - val_loss: 0.3659 - val_accuracy: 0.9045\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4420 - accuracy: 0.8682 - val_loss: 0.3649 - val_accuracy: 0.9057\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4287 - accuracy: 0.8709 - val_loss: 0.3628 - val_accuracy: 0.9057\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.4222 - accuracy: 0.8725 - val_loss: 0.3985 - val_accuracy: 0.8950\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 2s 45us/sample - loss: 0.4184 - accuracy: 0.8733 - val_loss: 0.3818 - val_accuracy: 0.9029\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.4278 - accuracy: 0.8714 - val_loss: 0.3889 - val_accuracy: 0.9007\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4194 - accuracy: 0.8738 - val_loss: 0.3788 - val_accuracy: 0.9039\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 2s 45us/sample - loss: 0.4078 - accuracy: 0.8780 - val_loss: 0.3838 - val_accuracy: 0.9002\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 0.4134 - accuracy: 0.8754 - val_loss: 0.4089 - val_accuracy: 0.8918\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4089 - accuracy: 0.8766 - val_loss: 0.4072 - val_accuracy: 0.8951\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4019 - accuracy: 0.8792 - val_loss: 0.3502 - val_accuracy: 0.9094\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3995 - accuracy: 0.8782 - val_loss: 0.3458 - val_accuracy: 0.9102\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3916 - accuracy: 0.8821 - val_loss: 0.3444 - val_accuracy: 0.9131\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3933 - accuracy: 0.8825 - val_loss: 0.3688 - val_accuracy: 0.9063\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.3869 - accuracy: 0.8829 - val_loss: 0.3845 - val_accuracy: 0.8983\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.3890 - accuracy: 0.8835 - val_loss: 0.3546 - val_accuracy: 0.9111\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3747 - accuracy: 0.8870 - val_loss: 0.3275 - val_accuracy: 0.9220\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3742 - accuracy: 0.8868 - val_loss: 0.3630 - val_accuracy: 0.9040\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.3693 - accuracy: 0.8880 - val_loss: 0.3569 - val_accuracy: 0.9102\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.3807 - accuracy: 0.8873 - val_loss: 0.3712 - val_accuracy: 0.9075\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3664 - accuracy: 0.8894 - val_loss: 0.3090 - val_accuracy: 0.9254\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3779 - accuracy: 0.8866 - val_loss: 0.3808 - val_accuracy: 0.9038\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3594 - accuracy: 0.8920 - val_loss: 0.3169 - val_accuracy: 0.9231\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3606 - accuracy: 0.8913 - val_loss: 0.3904 - val_accuracy: 0.8979\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 0.3656 - accuracy: 0.8898 - val_loss: 0.3245 - val_accuracy: 0.9210\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.3609 - accuracy: 0.8924 - val_loss: 0.3269 - val_accuracy: 0.9181\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3500 - accuracy: 0.8941 - val_loss: 0.3310 - val_accuracy: 0.9181\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3424 - accuracy: 0.8969 - val_loss: 0.3235 - val_accuracy: 0.9231\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3416 - accuracy: 0.8956 - val_loss: 0.3243 - val_accuracy: 0.9206\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3391 - accuracy: 0.8969 - val_loss: 0.3618 - val_accuracy: 0.9137\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 0.3492 - accuracy: 0.8940 - val_loss: 0.3698 - val_accuracy: 0.9029\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3372 - accuracy: 0.8994 - val_loss: 0.3199 - val_accuracy: 0.9248\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3586 - accuracy: 0.8920 - val_loss: 0.3169 - val_accuracy: 0.9245\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3407 - accuracy: 0.8968 - val_loss: 0.3542 - val_accuracy: 0.9157\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3451 - accuracy: 0.8971 - val_loss: 0.2962 - val_accuracy: 0.9277\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3312 - accuracy: 0.8991 - val_loss: 0.3170 - val_accuracy: 0.9231\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 0.3268 - accuracy: 0.9016 - val_loss: 0.3171 - val_accuracy: 0.923959 \n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3208 - accuracy: 0.9039 - val_loss: 0.3554 - val_accuracy: 0.9130\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3176 - accuracy: 0.9047 - val_loss: 0.3300 - val_accuracy: 0.9236\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3145 - accuracy: 0.9050 - val_loss: 0.3297 - val_accuracy: 0.9221\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3116 - accuracy: 0.9056 - val_loss: 0.3206 - val_accuracy: 0.9227\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3113 - accuracy: 0.9058 - val_loss: 0.3320 - val_accuracy: 0.9196\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3207 - accuracy: 0.9023 - val_loss: 0.3375 - val_accuracy: 0.9208\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3111 - accuracy: 0.9054 - val_loss: 0.3737 - val_accuracy: 0.9100\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.3316 - accuracy: 0.8995 - val_loss: 0.3430 - val_accuracy: 0.9160\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3266 - accuracy: 0.9014 - val_loss: 0.2963 - val_accuracy: 0.9304\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3067 - accuracy: 0.9042 - val_loss: 0.3723 - val_accuracy: 0.9115\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3221 - accuracy: 0.9014 - val_loss: 0.3935 - val_accuracy: 0.9046\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3189 - accuracy: 0.9020 - val_loss: 0.2906 - val_accuracy: 0.9340\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.3085 - accuracy: 0.9076 - val_loss: 0.3241 - val_accuracy: 0.9268\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2972 - accuracy: 0.9094 - val_loss: 0.3060 - val_accuracy: 0.9257\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3105 - accuracy: 0.9059 - val_loss: 0.3105 - val_accuracy: 0.9244\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3090 - accuracy: 0.9061 - val_loss: 0.3720 - val_accuracy: 0.9040\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3200 - accuracy: 0.9035 - val_loss: 0.3129 - val_accuracy: 0.9270\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2890 - accuracy: 0.9105 - val_loss: 0.3178 - val_accuracy: 0.9282\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3027 - accuracy: 0.9059 - val_loss: 0.3256 - val_accuracy: 0.9212\n",
      "test_score [0.5938363140291638, 0.85977775]\n",
      "Try 4/100: Best_val_acc: [0.5938363140291638, 0.85977775], lr: 1.3478205726330123e-05, Lambda: 1.4480935289667659e-07\n",
      "\n",
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 2.3350 - accuracy: 0.1119 - val_loss: 2.2934 - val_accuracy: 0.2214\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.1828 - accuracy: 0.1763 - val_loss: 2.2326 - val_accuracy: 0.2545\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 1.8982 - accuracy: 0.3031 - val_loss: 1.9469 - val_accuracy: 0.5938\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 1.6303 - accuracy: 0.4244 - val_loss: 1.6689 - val_accuracy: 0.6485\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.4309 - accuracy: 0.5137 - val_loss: 1.3996 - val_accuracy: 0.7280\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.2896 - accuracy: 0.5762 - val_loss: 1.2385 - val_accuracy: 0.7394\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 1.1936 - accuracy: 0.6157 - val_loss: 1.0467 - val_accuracy: 0.7639\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 1.1138 - accuracy: 0.6453 - val_loss: 0.9806 - val_accuracy: 0.7658\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.0567 - accuracy: 0.6687 - val_loss: 0.8230 - val_accuracy: 0.8026\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.9988 - accuracy: 0.6868 - val_loss: 0.7670 - val_accuracy: 0.8143\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9590 - accuracy: 0.7002 - val_loss: 0.7493 - val_accuracy: 0.8082\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9250 - accuracy: 0.7123 - val_loss: 0.6985 - val_accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8876 - accuracy: 0.7253 - val_loss: 0.6596 - val_accuracy: 0.8217\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8508 - accuracy: 0.7341 - val_loss: 0.6424 - val_accuracy: 0.8345\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8188 - accuracy: 0.7484 - val_loss: 0.6157 - val_accuracy: 0.8346\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 2s 41us/sample - loss: 0.8087 - accuracy: 0.7518 - val_loss: 0.6231 - val_accuracy: 0.8290\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 0.7720 - accuracy: 0.7609 - val_loss: 0.5978 - val_accuracy: 0.8386\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7619 - accuracy: 0.7675 - val_loss: 0.5711 - val_accuracy: 0.8438\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7344 - accuracy: 0.7727 - val_loss: 0.5279 - val_accuracy: 0.8624\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7104 - accuracy: 0.7847 - val_loss: 0.5607 - val_accuracy: 0.8514\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7048 - accuracy: 0.7835 - val_loss: 0.5391 - val_accuracy: 0.8587\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6893 - accuracy: 0.7905 - val_loss: 0.5195 - val_accuracy: 0.8635\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6714 - accuracy: 0.7973 - val_loss: 0.5165 - val_accuracy: 0.8614\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.6506 - accuracy: 0.8022 - val_loss: 0.4839 - val_accuracy: 0.8685\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6540 - accuracy: 0.8014 - val_loss: 0.4756 - val_accuracy: 0.8751\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6290 - accuracy: 0.8105 - val_loss: 0.5284 - val_accuracy: 0.8549\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6125 - accuracy: 0.8133 - val_loss: 0.4925 - val_accuracy: 0.8676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.5978 - accuracy: 0.8219 - val_loss: 0.4764 - val_accuracy: 0.8765- loss: 0.5992 - accuracy: 0.\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5814 - accuracy: 0.8227 - val_loss: 0.4750 - val_accuracy: 0.8732\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.5793 - accuracy: 0.8254 - val_loss: 0.5040 - val_accuracy: 0.8649\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.5643 - accuracy: 0.8321 - val_loss: 0.4724 - val_accuracy: 0.8737\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.5581 - accuracy: 0.8312 - val_loss: 0.4490 - val_accuracy: 0.8829\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.5518 - accuracy: 0.8337 - val_loss: 0.4176 - val_accuracy: 0.8915\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 3s 61us/sample - loss: 0.5450 - accuracy: 0.8354 - val_loss: 0.4546 - val_accuracy: 0.8782\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.5287 - accuracy: 0.8407 - val_loss: 0.4052 - val_accuracy: 0.8977\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.5181 - accuracy: 0.8449 - val_loss: 0.4491 - val_accuracy: 0.8774\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.5153 - accuracy: 0.8449 - val_loss: 0.4370 - val_accuracy: 0.8852\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5123 - accuracy: 0.8460 - val_loss: 0.5014 - val_accuracy: 0.8625\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5101 - accuracy: 0.8468 - val_loss: 0.4319 - val_accuracy: 0.8875\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5025 - accuracy: 0.8497 - val_loss: 0.4485 - val_accuracy: 0.8820\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4988 - accuracy: 0.8512 - val_loss: 0.3847 - val_accuracy: 0.9010\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4755 - accuracy: 0.8587 - val_loss: 0.4233 - val_accuracy: 0.8873\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4732 - accuracy: 0.8599 - val_loss: 0.3702 - val_accuracy: 0.9044\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.4619 - accuracy: 0.8640 - val_loss: 0.3829 - val_accuracy: 0.9045\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4632 - accuracy: 0.8622 - val_loss: 0.3826 - val_accuracy: 0.9023\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4521 - accuracy: 0.8640 - val_loss: 0.3660 - val_accuracy: 0.9074\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4481 - accuracy: 0.8654 - val_loss: 0.3769 - val_accuracy: 0.9030\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.4551 - accuracy: 0.8636 - val_loss: 0.4038 - val_accuracy: 0.8954\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4414 - accuracy: 0.8687 - val_loss: 0.3833 - val_accuracy: 0.9020\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4404 - accuracy: 0.8681 - val_loss: 0.3878 - val_accuracy: 0.9024\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4385 - accuracy: 0.8684 - val_loss: 0.4094 - val_accuracy: 0.8942\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4406 - accuracy: 0.8685 - val_loss: 0.3863 - val_accuracy: 0.9021\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.4202 - accuracy: 0.8750 - val_loss: 0.3435 - val_accuracy: 0.9137\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.4140 - accuracy: 0.8755 - val_loss: 0.3915 - val_accuracy: 0.8969\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4139 - accuracy: 0.8759 - val_loss: 0.3572 - val_accuracy: 0.9118\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4080 - accuracy: 0.8771 - val_loss: 0.4078 - val_accuracy: 0.8963\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4177 - accuracy: 0.8752 - val_loss: 0.3498 - val_accuracy: 0.9115\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4035 - accuracy: 0.8786 - val_loss: 0.3643 - val_accuracy: 0.9092\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4106 - accuracy: 0.8759 - val_loss: 0.3424 - val_accuracy: 0.9165\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3924 - accuracy: 0.8837 - val_loss: 0.3939 - val_accuracy: 0.9026\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.3927 - accuracy: 0.8827 - val_loss: 0.3803 - val_accuracy: 0.9051\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3881 - accuracy: 0.8830 - val_loss: 0.3582 - val_accuracy: 0.9125\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3866 - accuracy: 0.8844 - val_loss: 0.3503 - val_accuracy: 0.9124\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3844 - accuracy: 0.8854 - val_loss: 0.3828 - val_accuracy: 0.9045\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3833 - accuracy: 0.8855 - val_loss: 0.3620 - val_accuracy: 0.9099\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.3793 - accuracy: 0.8855 - val_loss: 0.3622 - val_accuracy: 0.9118\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.3788 - accuracy: 0.8862 - val_loss: 0.3352 - val_accuracy: 0.9206\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3738 - accuracy: 0.8868 - val_loss: 0.3824 - val_accuracy: 0.9049\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.3711 - accuracy: 0.8888 - val_loss: 0.3799 - val_accuracy: 0.9049\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.3872 - accuracy: 0.8848 - val_loss: 0.3497 - val_accuracy: 0.9171\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.3611 - accuracy: 0.8921 - val_loss: 0.3255 - val_accuracy: 0.9248\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 36us/sample - loss: 0.3534 - accuracy: 0.8929 - val_loss: 0.4019 - val_accuracy: 0.8987\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 36us/sample - loss: 0.3763 - accuracy: 0.8887 - val_loss: 0.3854 - val_accuracy: 0.9038\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.3620 - accuracy: 0.8918 - val_loss: 0.3612 - val_accuracy: 0.9112\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3579 - accuracy: 0.8932 - val_loss: 0.3359 - val_accuracy: 0.9179\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3441 - accuracy: 0.8977 - val_loss: 0.3324 - val_accuracy: 0.9208\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3394 - accuracy: 0.8988 - val_loss: 0.3509 - val_accuracy: 0.9156\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3508 - accuracy: 0.8945 - val_loss: 0.3368 - val_accuracy: 0.9200\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3354 - accuracy: 0.8983 - val_loss: 0.3198 - val_accuracy: 0.9240\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3439 - accuracy: 0.8955 - val_loss: 0.3147 - val_accuracy: 0.9256\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3361 - accuracy: 0.8978 - val_loss: 0.3416 - val_accuracy: 0.9155\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3375 - accuracy: 0.8998 - val_loss: 0.3406 - val_accuracy: 0.9206\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3407 - accuracy: 0.8965 - val_loss: 0.3434 - val_accuracy: 0.9177\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3358 - accuracy: 0.8997 - val_loss: 0.3338 - val_accuracy: 0.9219\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3333 - accuracy: 0.9001 - val_loss: 0.3360 - val_accuracy: 0.9200\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3329 - accuracy: 0.8997 - val_loss: 0.3434 - val_accuracy: 0.9167\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 2s 36us/sample - loss: 0.3292 - accuracy: 0.9010 - val_loss: 0.3102 - val_accuracy: 0.9273\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.3151 - accuracy: 0.9052 - val_loss: 0.3243 - val_accuracy: 0.9245\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3337 - accuracy: 0.8997 - val_loss: 0.3806 - val_accuracy: 0.9063\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3228 - accuracy: 0.9031 - val_loss: 0.3193 - val_accuracy: 0.9236\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3358 - accuracy: 0.8991 - val_loss: 0.3292 - val_accuracy: 0.9189\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.3166 - accuracy: 0.9033 - val_loss: 0.3079 - val_accuracy: 0.9290\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3246 - accuracy: 0.9019 - val_loss: 0.3853 - val_accuracy: 0.9029\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3145 - accuracy: 0.9065 - val_loss: 0.3077 - val_accuracy: 0.9302\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.3131 - accuracy: 0.9070 - val_loss: 0.3103 - val_accuracy: 0.9267\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.3055 - accuracy: 0.9078 - val_loss: 0.3138 - val_accuracy: 0.9267\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3098 - accuracy: 0.9048 - val_loss: 0.3345 - val_accuracy: 0.9215\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3065 - accuracy: 0.9076 - val_loss: 0.3254 - val_accuracy: 0.9240\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3228 - accuracy: 0.9034 - val_loss: 0.3143 - val_accuracy: 0.9256\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3004 - accuracy: 0.9096 - val_loss: 0.3078 - val_accuracy: 0.9261\n",
      "test_score [0.5786537980437279, 0.8578889]\n",
      "Try 5/100: Best_val_acc: [0.5786537980437279, 0.8578889], lr: 0.005671035628524862, Lambda: 1.8038721907332574e-05\n",
      "\n",
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 2.3816 - accuracy: 0.1271 - val_loss: 2.3564 - val_accuracy: 0.1183\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.1374 - accuracy: 0.2391 - val_loss: 2.2149 - val_accuracy: 0.4107\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 1.8041 - accuracy: 0.3869 - val_loss: 1.8789 - val_accuracy: 0.6226\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.5378 - accuracy: 0.4986 - val_loss: 1.6263 - val_accuracy: 0.6661\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 1.3700 - accuracy: 0.5675 - val_loss: 1.3115 - val_accuracy: 0.7527\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 1.2497 - accuracy: 0.6159 - val_loss: 1.1179 - val_accuracy: 0.7938\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.1705 - accuracy: 0.6418 - val_loss: 1.0194 - val_accuracy: 0.7768\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.0938 - accuracy: 0.6699 - val_loss: 0.8495 - val_accuracy: 0.8139\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0235 - accuracy: 0.6923 - val_loss: 0.7576 - val_accuracy: 0.8267\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9761 - accuracy: 0.7076 - val_loss: 0.7417 - val_accuracy: 0.8244\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9160 - accuracy: 0.7278 - val_loss: 0.6928 - val_accuracy: 0.8287\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.8901 - accuracy: 0.7385 - val_loss: 0.6533 - val_accuracy: 0.8288\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.8424 - accuracy: 0.7521 - val_loss: 0.6429 - val_accuracy: 0.8323\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8064 - accuracy: 0.7626 - val_loss: 0.6653 - val_accuracy: 0.8254\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7862 - accuracy: 0.7714 - val_loss: 0.6028 - val_accuracy: 0.8398\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7579 - accuracy: 0.7775 - val_loss: 0.5832 - val_accuracy: 0.8462\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7447 - accuracy: 0.7822 - val_loss: 0.5742 - val_accuracy: 0.8517\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.7076 - accuracy: 0.7940 - val_loss: 0.5544 - val_accuracy: 0.8535\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 0.6763 - accuracy: 0.8045 - val_loss: 0.5485 - val_accuracy: 0.8548\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6892 - accuracy: 0.7981 - val_loss: 0.5366 - val_accuracy: 0.8542\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6567 - accuracy: 0.8110 - val_loss: 0.5262 - val_accuracy: 0.8573\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6326 - accuracy: 0.8176 - val_loss: 0.5068 - val_accuracy: 0.8654\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6226 - accuracy: 0.8196 - val_loss: 0.4970 - val_accuracy: 0.8664\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6025 - accuracy: 0.8256 - val_loss: 0.4981 - val_accuracy: 0.8694\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5911 - accuracy: 0.8308 - val_loss: 0.4506 - val_accuracy: 0.8808\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5790 - accuracy: 0.8318 - val_loss: 0.4527 - val_accuracy: 0.8844\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.5751 - accuracy: 0.8336 - val_loss: 0.5056 - val_accuracy: 0.8669\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.5557 - accuracy: 0.8400 - val_loss: 0.4647 - val_accuracy: 0.8777\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5528 - accuracy: 0.8406 - val_loss: 0.4832 - val_accuracy: 0.8742\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5312 - accuracy: 0.8460 - val_loss: 0.4487 - val_accuracy: 0.8842\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.5241 - accuracy: 0.8496 - val_loss: 0.4879 - val_accuracy: 0.8695\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.5368 - accuracy: 0.8449 - val_loss: 0.4426 - val_accuracy: 0.8826\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5241 - accuracy: 0.8495 - val_loss: 0.4585 - val_accuracy: 0.8793\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5131 - accuracy: 0.8522 - val_loss: 0.4545 - val_accuracy: 0.8838\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.5060 - accuracy: 0.8542 - val_loss: 0.4250 - val_accuracy: 0.8876\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.5062 - accuracy: 0.8550 - val_loss: 0.4249 - val_accuracy: 0.8845\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4854 - accuracy: 0.8590 - val_loss: 0.4109 - val_accuracy: 0.8938\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4796 - accuracy: 0.8613 - val_loss: 0.4157 - val_accuracy: 0.8930\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4700 - accuracy: 0.8646 - val_loss: 0.3916 - val_accuracy: 0.9014\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4697 - accuracy: 0.8653 - val_loss: 0.3916 - val_accuracy: 0.9008\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 2s 41us/sample - loss: 0.4517 - accuracy: 0.8706 - val_loss: 0.3763 - val_accuracy: 0.9049\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.4522 - accuracy: 0.8709 - val_loss: 0.4274 - val_accuracy: 0.8881\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4510 - accuracy: 0.8683 - val_loss: 0.4214 - val_accuracy: 0.8920\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4489 - accuracy: 0.8703 - val_loss: 0.3955 - val_accuracy: 0.8975\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.4568 - accuracy: 0.8688 - val_loss: 0.3905 - val_accuracy: 0.8982\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4387 - accuracy: 0.8730 - val_loss: 0.3678 - val_accuracy: 0.9058\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.4296 - accuracy: 0.8755 - val_loss: 0.4296 - val_accuracy: 0.8869\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.4241 - accuracy: 0.8768 - val_loss: 0.4062 - val_accuracy: 0.8940\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4205 - accuracy: 0.8786 - val_loss: 0.4149 - val_accuracy: 0.8901\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4108 - accuracy: 0.8821 - val_loss: 0.3868 - val_accuracy: 0.8995\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4161 - accuracy: 0.8791 - val_loss: 0.4334 - val_accuracy: 0.8855\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4060 - accuracy: 0.8828 - val_loss: 0.3441 - val_accuracy: 0.9114\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4143 - accuracy: 0.8798 - val_loss: 0.3827 - val_accuracy: 0.9032\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4050 - accuracy: 0.8827 - val_loss: 0.3530 - val_accuracy: 0.9111\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3976 - accuracy: 0.8851 - val_loss: 0.3727 - val_accuracy: 0.9067\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3993 - accuracy: 0.8851 - val_loss: 0.3816 - val_accuracy: 0.9014\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.3875 - accuracy: 0.8882 - val_loss: 0.3501 - val_accuracy: 0.9125\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3875 - accuracy: 0.8862 - val_loss: 0.3438 - val_accuracy: 0.9146\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3826 - accuracy: 0.8912 - val_loss: 0.3416 - val_accuracy: 0.9129\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.3699 - accuracy: 0.8923 - val_loss: 0.3569 - val_accuracy: 0.9083\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.3817 - accuracy: 0.8901 - val_loss: 0.3566 - val_accuracy: 0.9088\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3690 - accuracy: 0.8947 - val_loss: 0.3426 - val_accuracy: 0.9142\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3757 - accuracy: 0.8921 - val_loss: 0.3249 - val_accuracy: 0.9189\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3635 - accuracy: 0.8952 - val_loss: 0.3357 - val_accuracy: 0.9170\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.3593 - accuracy: 0.8966 - val_loss: 0.3559 - val_accuracy: 0.9117\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3705 - accuracy: 0.8943 - val_loss: 0.3697 - val_accuracy: 0.9081\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3575 - accuracy: 0.8976 - val_loss: 0.3942 - val_accuracy: 0.8982\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3591 - accuracy: 0.8971 - val_loss: 0.3974 - val_accuracy: 0.8971\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3611 - accuracy: 0.8950 - val_loss: 0.3680 - val_accuracy: 0.9051\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.3404 - accuracy: 0.9017 - val_loss: 0.3733 - val_accuracy: 0.9020\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3523 - accuracy: 0.8978 - val_loss: 0.3124 - val_accuracy: 0.9238\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.3497 - accuracy: 0.8982 - val_loss: 0.3244 - val_accuracy: 0.9219\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.3465 - accuracy: 0.9016 - val_loss: 0.3153 - val_accuracy: 0.9220\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3362 - accuracy: 0.9014 - val_loss: 0.3240 - val_accuracy: 0.9188\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3326 - accuracy: 0.9029 - val_loss: 0.3049 - val_accuracy: 0.9235\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3355 - accuracy: 0.9020 - val_loss: 0.3239 - val_accuracy: 0.9225\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3321 - accuracy: 0.9025 - val_loss: 0.3041 - val_accuracy: 0.9267\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3349 - accuracy: 0.9029 - val_loss: 0.3428 - val_accuracy: 0.9130\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3369 - accuracy: 0.9015 - val_loss: 0.3066 - val_accuracy: 0.9276\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3209 - accuracy: 0.9068 - val_loss: 0.3331 - val_accuracy: 0.9201\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3272 - accuracy: 0.9049 - val_loss: 0.3334 - val_accuracy: 0.9177\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 2s 36us/sample - loss: 0.3213 - accuracy: 0.9069 - val_loss: 0.3229 - val_accuracy: 0.9225\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.3237 - accuracy: 0.9073 - val_loss: 0.3310 - val_accuracy: 0.9211\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3234 - accuracy: 0.9065 - val_loss: 0.3233 - val_accuracy: 0.9199\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3350 - accuracy: 0.9035 - val_loss: 0.3082 - val_accuracy: 0.9265\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3086 - accuracy: 0.9103 - val_loss: 0.3173 - val_accuracy: 0.9248\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3239 - accuracy: 0.9064 - val_loss: 0.3251 - val_accuracy: 0.9220\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 0.3205 - accuracy: 0.9079 - val_loss: 0.3148 - val_accuracy: 0.9238\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 0.3126 - accuracy: 0.9095 - val_loss: 0.3337 - val_accuracy: 0.9202\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3140 - accuracy: 0.9072 - val_loss: 0.4008 - val_accuracy: 0.8996\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3195 - accuracy: 0.9098 - val_loss: 0.3401 - val_accuracy: 0.9144\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 2s 37us/sample - loss: 0.3049 - accuracy: 0.9095 - val_loss: 0.3094 - val_accuracy: 0.9245\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2959 - accuracy: 0.9135 - val_loss: 0.3164 - val_accuracy: 0.9236\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.2989 - accuracy: 0.9128 - val_loss: 0.3409 - val_accuracy: 0.9201\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3041 - accuracy: 0.9103 - val_loss: 0.2866 - val_accuracy: 0.9333\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2972 - accuracy: 0.9118 - val_loss: 0.2870 - val_accuracy: 0.9332\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3002 - accuracy: 0.9126 - val_loss: 0.3134 - val_accuracy: 0.9226\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2865 - accuracy: 0.9156 - val_loss: 0.2947 - val_accuracy: 0.9294\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.2982 - accuracy: 0.9134 - val_loss: 0.2859 - val_accuracy: 0.9332\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.2972 - accuracy: 0.9129 - val_loss: 0.2833 - val_accuracy: 0.9317\n",
      "test_score [0.543610353483094, 0.8661111]\n",
      "Try 6/100: Best_val_acc: [0.543610353483094, 0.8661111], lr: 5.3018589037369146e-05, Lambda: 0.004780313883968358\n",
      "\n",
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 2.3287 - accuracy: 0.1212 - val_loss: 2.2980 - val_accuracy: 0.0224\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 2.1584 - accuracy: 0.2024 - val_loss: 2.1913 - val_accuracy: 0.3956\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.8909 - accuracy: 0.3251 - val_loss: 1.9202 - val_accuracy: 0.5600\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.6087 - accuracy: 0.4522 - val_loss: 1.5701 - val_accuracy: 0.6500\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.4056 - accuracy: 0.5311 - val_loss: 1.3891 - val_accuracy: 0.6706\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 1.2719 - accuracy: 0.5831 - val_loss: 1.1742 - val_accuracy: 0.7211\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 1.1807 - accuracy: 0.6178 - val_loss: 1.0198 - val_accuracy: 0.7569\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.1050 - accuracy: 0.6510 - val_loss: 0.9271 - val_accuracy: 0.7646\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0422 - accuracy: 0.6694 - val_loss: 0.8464 - val_accuracy: 0.7873\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9846 - accuracy: 0.6913 - val_loss: 0.7828 - val_accuracy: 0.8024\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9360 - accuracy: 0.7096 - val_loss: 0.6636 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9091 - accuracy: 0.7161 - val_loss: 0.6590 - val_accuracy: 0.8275\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8695 - accuracy: 0.7340 - val_loss: 0.6399 - val_accuracy: 0.8358\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.8358 - accuracy: 0.7425 - val_loss: 0.6371 - val_accuracy: 0.8352\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8148 - accuracy: 0.7491 - val_loss: 0.6204 - val_accuracy: 0.8410\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7847 - accuracy: 0.7591 - val_loss: 0.6180 - val_accuracy: 0.8332\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7514 - accuracy: 0.7730 - val_loss: 0.5503 - val_accuracy: 0.8549\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7237 - accuracy: 0.7804 - val_loss: 0.5753 - val_accuracy: 0.8445\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 0.7258 - accuracy: 0.7797 - val_loss: 0.5478 - val_accuracy: 0.8561\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.6960 - accuracy: 0.7874 - val_loss: 0.5699 - val_accuracy: 0.8450\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6737 - accuracy: 0.7957 - val_loss: 0.5459 - val_accuracy: 0.8567\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6486 - accuracy: 0.8038 - val_loss: 0.5379 - val_accuracy: 0.8605\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6446 - accuracy: 0.8068 - val_loss: 0.5434 - val_accuracy: 0.8562\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6258 - accuracy: 0.8106 - val_loss: 0.4599 - val_accuracy: 0.8806\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6118 - accuracy: 0.8160 - val_loss: 0.4830 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6092 - accuracy: 0.8170 - val_loss: 0.4991 - val_accuracy: 0.8670\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.5845 - accuracy: 0.8242 - val_loss: 0.4847 - val_accuracy: 0.8729\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5816 - accuracy: 0.8260 - val_loss: 0.4620 - val_accuracy: 0.8757\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5691 - accuracy: 0.8278 - val_loss: 0.4474 - val_accuracy: 0.8786\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5721 - accuracy: 0.8275 - val_loss: 0.4366 - val_accuracy: 0.8880\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5456 - accuracy: 0.8374 - val_loss: 0.4663 - val_accuracy: 0.8757\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.5454 - accuracy: 0.8378 - val_loss: 0.4905 - val_accuracy: 0.8680\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 0.5327 - accuracy: 0.8400 - val_loss: 0.4442 - val_accuracy: 0.8849\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5233 - accuracy: 0.8448 - val_loss: 0.4052 - val_accuracy: 0.8949\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5260 - accuracy: 0.8422 - val_loss: 0.4506 - val_accuracy: 0.8825\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 0.5092 - accuracy: 0.8474 - val_loss: 0.4669 - val_accuracy: 0.8767\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 0.4995 - accuracy: 0.8513 - val_loss: 0.4160 - val_accuracy: 0.8920\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4968 - accuracy: 0.8513 - val_loss: 0.4524 - val_accuracy: 0.8814\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4918 - accuracy: 0.8523 - val_loss: 0.4172 - val_accuracy: 0.8886\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 2s 38us/sample - loss: 0.4927 - accuracy: 0.8521 - val_loss: 0.4057 - val_accuracy: 0.8982\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.4804 - accuracy: 0.8565 - val_loss: 0.3946 - val_accuracy: 0.8994\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4747 - accuracy: 0.8555 - val_loss: 0.4131 - val_accuracy: 0.8915\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4692 - accuracy: 0.8604 - val_loss: 0.4190 - val_accuracy: 0.8930\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4624 - accuracy: 0.8620 - val_loss: 0.3764 - val_accuracy: 0.9035\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4621 - accuracy: 0.8618 - val_loss: 0.3964 - val_accuracy: 0.8956\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4484 - accuracy: 0.8665 - val_loss: 0.3994 - val_accuracy: 0.8961\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4426 - accuracy: 0.8690 - val_loss: 0.3498 - val_accuracy: 0.9123\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4299 - accuracy: 0.8709 - val_loss: 0.3663 - val_accuracy: 0.9042\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4378 - accuracy: 0.8703 - val_loss: 0.3933 - val_accuracy: 0.8936\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4261 - accuracy: 0.8738 - val_loss: 0.3605 - val_accuracy: 0.9107\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4190 - accuracy: 0.8752 - val_loss: 0.4160 - val_accuracy: 0.8912\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4373 - accuracy: 0.8700 - val_loss: 0.3715 - val_accuracy: 0.9073\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.4222 - accuracy: 0.8739 - val_loss: 0.3782 - val_accuracy: 0.9054\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4037 - accuracy: 0.8801 - val_loss: 0.3607 - val_accuracy: 0.9106\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.4128 - accuracy: 0.8754 - val_loss: 0.3539 - val_accuracy: 0.9102\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 0.4045 - accuracy: 0.8799 - val_loss: 0.3888 - val_accuracy: 0.9035\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4140 - accuracy: 0.8775 - val_loss: 0.3697 - val_accuracy: 0.9064\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3912 - accuracy: 0.8823 - val_loss: 0.3812 - val_accuracy: 0.9040\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3883 - accuracy: 0.8829 - val_loss: 0.3506 - val_accuracy: 0.9125\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3925 - accuracy: 0.8833 - val_loss: 0.3508 - val_accuracy: 0.9111\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.3979 - accuracy: 0.8813 - val_loss: 0.4054 - val_accuracy: 0.8977\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 2s 36us/sample - loss: 0.3865 - accuracy: 0.8837 - val_loss: 0.3721 - val_accuracy: 0.9063\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3824 - accuracy: 0.8849 - val_loss: 0.3604 - val_accuracy: 0.9087\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3787 - accuracy: 0.8876 - val_loss: 0.3314 - val_accuracy: 0.9137\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3827 - accuracy: 0.8845 - val_loss: 0.3782 - val_accuracy: 0.9050\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3771 - accuracy: 0.8871 - val_loss: 0.3408 - val_accuracy: 0.9143\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 0.3735 - accuracy: 0.8869 - val_loss: 0.3559 - val_accuracy: 0.9070\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3676 - accuracy: 0.8906 - val_loss: 0.3567 - val_accuracy: 0.9083\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3660 - accuracy: 0.8896 - val_loss: 0.3389 - val_accuracy: 0.9165\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3587 - accuracy: 0.8930 - val_loss: 0.3321 - val_accuracy: 0.9162\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.3651 - accuracy: 0.8906 - val_loss: 0.3322 - val_accuracy: 0.9205\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.3858 - accuracy: 0.8845 - val_loss: 0.3062 - val_accuracy: 0.9252\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3599 - accuracy: 0.8929 - val_loss: 0.3475 - val_accuracy: 0.9142\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3649 - accuracy: 0.8900 - val_loss: 0.3100 - val_accuracy: 0.9199\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3599 - accuracy: 0.8934 - val_loss: 0.3370 - val_accuracy: 0.9185\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.3591 - accuracy: 0.8900 - val_loss: 0.3427 - val_accuracy: 0.9094\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 0.3513 - accuracy: 0.8960 - val_loss: 0.3603 - val_accuracy: 0.9106\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3439 - accuracy: 0.8973 - val_loss: 0.3070 - val_accuracy: 0.9239\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3420 - accuracy: 0.8973 - val_loss: 0.3336 - val_accuracy: 0.9127\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3359 - accuracy: 0.8990 - val_loss: 0.3491 - val_accuracy: 0.9083\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.3421 - accuracy: 0.8948 - val_loss: 0.3755 - val_accuracy: 0.9031\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3313 - accuracy: 0.9007 - val_loss: 0.3647 - val_accuracy: 0.9118\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3418 - accuracy: 0.8973 - val_loss: 0.3369 - val_accuracy: 0.9137\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3433 - accuracy: 0.8964 - val_loss: 0.3277 - val_accuracy: 0.9190\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3235 - accuracy: 0.9032 - val_loss: 0.3343 - val_accuracy: 0.9168\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3231 - accuracy: 0.9027 - val_loss: 0.3468 - val_accuracy: 0.9169\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3251 - accuracy: 0.9032 - val_loss: 0.3161 - val_accuracy: 0.9195\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.3314 - accuracy: 0.9009 - val_loss: 0.3232 - val_accuracy: 0.9218\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3271 - accuracy: 0.9001 - val_loss: 0.3124 - val_accuracy: 0.9246\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.3197 - accuracy: 0.9050 - val_loss: 0.3309 - val_accuracy: 0.9219\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 2s 41us/sample - loss: 0.3092 - accuracy: 0.9071 - val_loss: 0.3080 - val_accuracy: 0.9246\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3119 - accuracy: 0.9063 - val_loss: 0.3308 - val_accuracy: 0.9214\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3098 - accuracy: 0.9067 - val_loss: 0.3143 - val_accuracy: 0.9252\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3013 - accuracy: 0.9093 - val_loss: 0.3460 - val_accuracy: 0.9113\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3181 - accuracy: 0.9055 - val_loss: 0.3083 - val_accuracy: 0.9236\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.3050 - accuracy: 0.9068 - val_loss: 0.3155 - val_accuracy: 0.9245\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3050 - accuracy: 0.9076 - val_loss: 0.3248 - val_accuracy: 0.9226\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3084 - accuracy: 0.9071 - val_loss: 0.3433 - val_accuracy: 0.9170\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3018 - accuracy: 0.9094 - val_loss: 0.3136 - val_accuracy: 0.9233\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2967 - accuracy: 0.9119 - val_loss: 0.3254 - val_accuracy: 0.9239\n",
      "test_score [0.5502061609162224, 0.8635]\n",
      "Try 7/100: Best_val_acc: [0.5502061609162224, 0.8635], lr: 4.687054151938263e-05, Lambda: 2.005904082580508e-06\n",
      "\n",
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 2.3247 - accuracy: 0.1212 - val_loss: 2.3117 - val_accuracy: 0.0164\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.1556 - accuracy: 0.2084 - val_loss: 2.2602 - val_accuracy: 0.0770\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.8778 - accuracy: 0.3322 - val_loss: 1.9462 - val_accuracy: 0.4632\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.5920 - accuracy: 0.4599 - val_loss: 1.6639 - val_accuracy: 0.6036\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.3906 - accuracy: 0.5420 - val_loss: 1.3526 - val_accuracy: 0.6807\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 1.2389 - accuracy: 0.6053 - val_loss: 1.2067 - val_accuracy: 0.7018\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.1534 - accuracy: 0.6355 - val_loss: 1.0448 - val_accuracy: 0.7363\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.0749 - accuracy: 0.6661 - val_loss: 0.9265 - val_accuracy: 0.7715\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 1.0184 - accuracy: 0.6821 - val_loss: 0.8550 - val_accuracy: 0.7746\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.9672 - accuracy: 0.7018 - val_loss: 0.7050 - val_accuracy: 0.8223\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9273 - accuracy: 0.7156 - val_loss: 0.7233 - val_accuracy: 0.8129\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8929 - accuracy: 0.7269 - val_loss: 0.7396 - val_accuracy: 0.7943\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8557 - accuracy: 0.7412 - val_loss: 0.6333 - val_accuracy: 0.8285\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8322 - accuracy: 0.7463 - val_loss: 0.6464 - val_accuracy: 0.8225\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7946 - accuracy: 0.7585 - val_loss: 0.5708 - val_accuracy: 0.8462\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7640 - accuracy: 0.7673 - val_loss: 0.5696 - val_accuracy: 0.8467\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7459 - accuracy: 0.7750 - val_loss: 0.6144 - val_accuracy: 0.8258\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 2s 45us/sample - loss: 0.7419 - accuracy: 0.7761 - val_loss: 0.5943 - val_accuracy: 0.8293\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.7086 - accuracy: 0.7867 - val_loss: 0.5700 - val_accuracy: 0.8418\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6958 - accuracy: 0.7921 - val_loss: 0.5096 - val_accuracy: 0.8625\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6784 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.8644\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6503 - accuracy: 0.8045 - val_loss: 0.5207 - val_accuracy: 0.8555\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6551 - accuracy: 0.8040 - val_loss: 0.5369 - val_accuracy: 0.8480\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.6306 - accuracy: 0.8137 - val_loss: 0.5382 - val_accuracy: 0.8511\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6143 - accuracy: 0.8169 - val_loss: 0.4875 - val_accuracy: 0.8676\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6051 - accuracy: 0.8175 - val_loss: 0.4838 - val_accuracy: 0.8671\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5966 - accuracy: 0.8204 - val_loss: 0.4603 - val_accuracy: 0.8726\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.5810 - accuracy: 0.8272 - val_loss: 0.4905 - val_accuracy: 0.8633\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5654 - accuracy: 0.8317 - val_loss: 0.4407 - val_accuracy: 0.8874\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5590 - accuracy: 0.8314 - val_loss: 0.4375 - val_accuracy: 0.8856\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5638 - accuracy: 0.8330 - val_loss: 0.5126 - val_accuracy: 0.8575\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5496 - accuracy: 0.8354 - val_loss: 0.4402 - val_accuracy: 0.8781\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5339 - accuracy: 0.8422 - val_loss: 0.4604 - val_accuracy: 0.8750\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5224 - accuracy: 0.8452 - val_loss: 0.4319 - val_accuracy: 0.8806\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.5167 - accuracy: 0.8464 - val_loss: 0.4383 - val_accuracy: 0.8845\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5260 - accuracy: 0.8457 - val_loss: 0.4184 - val_accuracy: 0.8867\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5063 - accuracy: 0.8522 - val_loss: 0.4108 - val_accuracy: 0.8935\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5015 - accuracy: 0.8520 - val_loss: 0.4185 - val_accuracy: 0.8908\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4928 - accuracy: 0.8533 - val_loss: 0.4505 - val_accuracy: 0.8771\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4957 - accuracy: 0.8531 - val_loss: 0.3923 - val_accuracy: 0.9013\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4763 - accuracy: 0.8599 - val_loss: 0.3894 - val_accuracy: 0.8970\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.4709 - accuracy: 0.8612 - val_loss: 0.4039 - val_accuracy: 0.8940\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.4629 - accuracy: 0.8628 - val_loss: 0.3973 - val_accuracy: 0.8998\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4530 - accuracy: 0.8671 - val_loss: 0.4135 - val_accuracy: 0.8915\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4564 - accuracy: 0.8644 - val_loss: 0.4320 - val_accuracy: 0.8876\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 2s 45us/sample - loss: 0.4660 - accuracy: 0.8627 - val_loss: 0.3863 - val_accuracy: 0.8954\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 2s 41us/sample - loss: 0.4529 - accuracy: 0.8675 - val_loss: 0.4000 - val_accuracy: 0.8965\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4320 - accuracy: 0.8729 - val_loss: 0.3962 - val_accuracy: 0.8960\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4380 - accuracy: 0.8687 - val_loss: 0.4053 - val_accuracy: 0.8943\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.4305 - accuracy: 0.8724 - val_loss: 0.4194 - val_accuracy: 0.8899\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 0.4305 - accuracy: 0.8723 - val_loss: 0.3651 - val_accuracy: 0.9056\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4228 - accuracy: 0.8760 - val_loss: 0.3807 - val_accuracy: 0.9026\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4154 - accuracy: 0.8783 - val_loss: 0.3629 - val_accuracy: 0.9079\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4210 - accuracy: 0.8751 - val_loss: 0.3929 - val_accuracy: 0.8996\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4062 - accuracy: 0.8805 - val_loss: 0.3531 - val_accuracy: 0.9113\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4028 - accuracy: 0.8816 - val_loss: 0.3710 - val_accuracy: 0.9058\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.4027 - accuracy: 0.8805 - val_loss: 0.3451 - val_accuracy: 0.9130\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.3960 - accuracy: 0.8825 - val_loss: 0.3714 - val_accuracy: 0.9045\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4102 - accuracy: 0.8803 - val_loss: 0.3681 - val_accuracy: 0.9056\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4037 - accuracy: 0.8818 - val_loss: 0.3819 - val_accuracy: 0.8980\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.3932 - accuracy: 0.8844 - val_loss: 0.3494 - val_accuracy: 0.9119\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.3793 - accuracy: 0.8885 - val_loss: 0.3595 - val_accuracy: 0.9062\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3845 - accuracy: 0.8870 - val_loss: 0.3453 - val_accuracy: 0.9118\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3851 - accuracy: 0.8864 - val_loss: 0.3784 - val_accuracy: 0.9049\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3701 - accuracy: 0.8911 - val_loss: 0.3815 - val_accuracy: 0.9033\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3856 - accuracy: 0.8888 - val_loss: 0.3294 - val_accuracy: 0.9164\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.3626 - accuracy: 0.8922 - val_loss: 0.3603 - val_accuracy: 0.9056\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3677 - accuracy: 0.8914 - val_loss: 0.3278 - val_accuracy: 0.9174\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3712 - accuracy: 0.8908 - val_loss: 0.3447 - val_accuracy: 0.9125\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3644 - accuracy: 0.8935 - val_loss: 0.3391 - val_accuracy: 0.9148\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.3585 - accuracy: 0.8928 - val_loss: 0.3298 - val_accuracy: 0.9183\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3503 - accuracy: 0.8985 - val_loss: 0.3470 - val_accuracy: 0.9146\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3613 - accuracy: 0.8934 - val_loss: 0.3705 - val_accuracy: 0.9045\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3551 - accuracy: 0.8956 - val_loss: 0.3421 - val_accuracy: 0.9138\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3511 - accuracy: 0.8977 - val_loss: 0.3130 - val_accuracy: 0.9237\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3400 - accuracy: 0.8995 - val_loss: 0.3208 - val_accuracy: 0.9223\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3456 - accuracy: 0.8990 - val_loss: 0.3411 - val_accuracy: 0.9151\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3385 - accuracy: 0.9000 - val_loss: 0.3216 - val_accuracy: 0.9201\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3414 - accuracy: 0.8994 - val_loss: 0.3347 - val_accuracy: 0.9188\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.3398 - accuracy: 0.8994 - val_loss: 0.2787 - val_accuracy: 0.9336\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3437 - accuracy: 0.8983 - val_loss: 0.3333 - val_accuracy: 0.9156\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3333 - accuracy: 0.9008 - val_loss: 0.3380 - val_accuracy: 0.9167\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3384 - accuracy: 0.9002 - val_loss: 0.3011 - val_accuracy: 0.9283\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3217 - accuracy: 0.9046 - val_loss: 0.3390 - val_accuracy: 0.9211\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3269 - accuracy: 0.9038 - val_loss: 0.3299 - val_accuracy: 0.9194\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3230 - accuracy: 0.9043 - val_loss: 0.2973 - val_accuracy: 0.9298\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.3232 - accuracy: 0.9041 - val_loss: 0.3144 - val_accuracy: 0.9250\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3274 - accuracy: 0.9013 - val_loss: 0.2998 - val_accuracy: 0.9275\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.3122 - accuracy: 0.9085 - val_loss: 0.3086 - val_accuracy: 0.9251\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.3199 - accuracy: 0.9063 - val_loss: 0.3141 - val_accuracy: 0.9262\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3085 - accuracy: 0.9073 - val_loss: 0.3229 - val_accuracy: 0.9214\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3124 - accuracy: 0.9085 - val_loss: 0.3183 - val_accuracy: 0.9249\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3105 - accuracy: 0.9078 - val_loss: 0.3754 - val_accuracy: 0.9061\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3208 - accuracy: 0.9031 - val_loss: 0.3478 - val_accuracy: 0.9146\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3124 - accuracy: 0.9076 - val_loss: 0.3019 - val_accuracy: 0.9276\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3168 - accuracy: 0.9061 - val_loss: 0.3095 - val_accuracy: 0.9258\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2957 - accuracy: 0.9126 - val_loss: 0.3018 - val_accuracy: 0.9301\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 0.3016 - accuracy: 0.9104 - val_loss: 0.3252 - val_accuracy: 0.9220\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2987 - accuracy: 0.9119 - val_loss: 0.3467 - val_accuracy: 0.9143\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3053 - accuracy: 0.9095 - val_loss: 0.3386 - val_accuracy: 0.9170\n",
      "test_score [0.5765388304127588, 0.8571111]\n",
      "Try 8/100: Best_val_acc: [0.5765388304127588, 0.8571111], lr: 9.188463380149603e-05, Lambda: 0.00047137570249674616\n",
      "\n",
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 2.3044 - accuracy: 0.1245 - val_loss: 2.2917 - val_accuracy: 0.0742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 2.1098 - accuracy: 0.2201 - val_loss: 2.1543 - val_accuracy: 0.3861\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.8058 - accuracy: 0.3588 - val_loss: 1.9330 - val_accuracy: 0.4801\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.5446 - accuracy: 0.4720 - val_loss: 1.6161 - val_accuracy: 0.6051\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.3639 - accuracy: 0.5516 - val_loss: 1.3588 - val_accuracy: 0.6788\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.2278 - accuracy: 0.6034 - val_loss: 1.2965 - val_accuracy: 0.6738\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.1472 - accuracy: 0.6345 - val_loss: 1.0074 - val_accuracy: 0.7611\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.0584 - accuracy: 0.6675 - val_loss: 0.9991 - val_accuracy: 0.7330\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0250 - accuracy: 0.6817 - val_loss: 0.8833 - val_accuracy: 0.7690\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.9643 - accuracy: 0.7015 - val_loss: 0.8034 - val_accuracy: 0.7848\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9295 - accuracy: 0.7137 - val_loss: 0.7310 - val_accuracy: 0.8137\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8943 - accuracy: 0.7237 - val_loss: 0.7081 - val_accuracy: 0.8139\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8559 - accuracy: 0.7370 - val_loss: 0.6542 - val_accuracy: 0.8245\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.8205 - accuracy: 0.7493 - val_loss: 0.6262 - val_accuracy: 0.8305\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8028 - accuracy: 0.7570 - val_loss: 0.6507 - val_accuracy: 0.8182\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7724 - accuracy: 0.7652 - val_loss: 0.6144 - val_accuracy: 0.8356\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7512 - accuracy: 0.7735 - val_loss: 0.5910 - val_accuracy: 0.8489\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7234 - accuracy: 0.7808 - val_loss: 0.5892 - val_accuracy: 0.8331\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7046 - accuracy: 0.7876 - val_loss: 0.6123 - val_accuracy: 0.8301\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.6839 - accuracy: 0.7950 - val_loss: 0.5401 - val_accuracy: 0.8542\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6802 - accuracy: 0.7935 - val_loss: 0.5264 - val_accuracy: 0.8599\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6466 - accuracy: 0.8053 - val_loss: 0.5366 - val_accuracy: 0.8506\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6295 - accuracy: 0.8088 - val_loss: 0.5010 - val_accuracy: 0.8631\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6356 - accuracy: 0.8094 - val_loss: 0.4893 - val_accuracy: 0.8715\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 0.6171 - accuracy: 0.8162 - val_loss: 0.5183 - val_accuracy: 0.8610\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.5908 - accuracy: 0.8250 - val_loss: 0.4929 - val_accuracy: 0.8670\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5902 - accuracy: 0.8220 - val_loss: 0.4965 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5675 - accuracy: 0.8310 - val_loss: 0.4365 - val_accuracy: 0.8857\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5603 - accuracy: 0.8323 - val_loss: 0.5107 - val_accuracy: 0.8602\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5583 - accuracy: 0.8324 - val_loss: 0.5029 - val_accuracy: 0.8642\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5501 - accuracy: 0.8370 - val_loss: 0.4263 - val_accuracy: 0.8913\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5392 - accuracy: 0.8400 - val_loss: 0.4219 - val_accuracy: 0.8935\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.5261 - accuracy: 0.8438 - val_loss: 0.4220 - val_accuracy: 0.8883\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.5190 - accuracy: 0.8453 - val_loss: 0.4398 - val_accuracy: 0.8854\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.5126 - accuracy: 0.8464 - val_loss: 0.4731 - val_accuracy: 0.8735\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 2s 36us/sample - loss: 0.5045 - accuracy: 0.8486 - val_loss: 0.4651 - val_accuracy: 0.8800\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.5135 - accuracy: 0.8471 - val_loss: 0.5166 - val_accuracy: 0.8580\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4936 - accuracy: 0.8518 - val_loss: 0.4091 - val_accuracy: 0.8948\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4859 - accuracy: 0.8540 - val_loss: 0.4250 - val_accuracy: 0.8919\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4739 - accuracy: 0.8576 - val_loss: 0.4224 - val_accuracy: 0.8879\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4571 - accuracy: 0.8643 - val_loss: 0.4153 - val_accuracy: 0.8904\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 0.4634 - accuracy: 0.8637 - val_loss: 0.3799 - val_accuracy: 0.9037\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 2s 41us/sample - loss: 0.4680 - accuracy: 0.8604 - val_loss: 0.4548 - val_accuracy: 0.8813\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4666 - accuracy: 0.8601 - val_loss: 0.3921 - val_accuracy: 0.8964\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4581 - accuracy: 0.8638 - val_loss: 0.4120 - val_accuracy: 0.8945\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.4441 - accuracy: 0.8673 - val_loss: 0.3993 - val_accuracy: 0.8980\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4445 - accuracy: 0.8669 - val_loss: 0.3550 - val_accuracy: 0.9119\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4282 - accuracy: 0.8714 - val_loss: 0.3757 - val_accuracy: 0.9050\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4267 - accuracy: 0.8721 - val_loss: 0.3599 - val_accuracy: 0.9092\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4148 - accuracy: 0.8769 - val_loss: 0.3810 - val_accuracy: 0.9010\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 2s 45us/sample - loss: 0.4045 - accuracy: 0.8807 - val_loss: 0.3755 - val_accuracy: 0.9040\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 0.4179 - accuracy: 0.8767 - val_loss: 0.3541 - val_accuracy: 0.9117\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4245 - accuracy: 0.8742 - val_loss: 0.3534 - val_accuracy: 0.9089\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4046 - accuracy: 0.8784 - val_loss: 0.3286 - val_accuracy: 0.9187\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3941 - accuracy: 0.8825 - val_loss: 0.3257 - val_accuracy: 0.9169\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3949 - accuracy: 0.8823 - val_loss: 0.3850 - val_accuracy: 0.9014\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3995 - accuracy: 0.8810 - val_loss: 0.4098 - val_accuracy: 0.8948\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3899 - accuracy: 0.8836 - val_loss: 0.3503 - val_accuracy: 0.9127\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.3928 - accuracy: 0.8827 - val_loss: 0.3274 - val_accuracy: 0.9183\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3735 - accuracy: 0.8893 - val_loss: 0.3845 - val_accuracy: 0.9012\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3978 - accuracy: 0.8802 - val_loss: 0.3731 - val_accuracy: 0.9067\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3805 - accuracy: 0.8859 - val_loss: 0.3627 - val_accuracy: 0.9108\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.3720 - accuracy: 0.8891 - val_loss: 0.3700 - val_accuracy: 0.9088\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3703 - accuracy: 0.8893 - val_loss: 0.3425 - val_accuracy: 0.9171\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3706 - accuracy: 0.8867 - val_loss: 0.3655 - val_accuracy: 0.9065\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3659 - accuracy: 0.8919 - val_loss: 0.3413 - val_accuracy: 0.9163\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3582 - accuracy: 0.8925 - val_loss: 0.3696 - val_accuracy: 0.9021\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 0.3603 - accuracy: 0.8917 - val_loss: 0.3207 - val_accuracy: 0.9192\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.3545 - accuracy: 0.8937 - val_loss: 0.3795 - val_accuracy: 0.9027\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3490 - accuracy: 0.8954 - val_loss: 0.3530 - val_accuracy: 0.9125\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3485 - accuracy: 0.8942 - val_loss: 0.3302 - val_accuracy: 0.9179\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3509 - accuracy: 0.8960 - val_loss: 0.3472 - val_accuracy: 0.9155\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3477 - accuracy: 0.8961 - val_loss: 0.3397 - val_accuracy: 0.9170\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3363 - accuracy: 0.8995 - val_loss: 0.3220 - val_accuracy: 0.9189\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3465 - accuracy: 0.8957 - val_loss: 0.3549 - val_accuracy: 0.9108\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.3453 - accuracy: 0.8951 - val_loss: 0.3205 - val_accuracy: 0.9225\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3362 - accuracy: 0.8995 - val_loss: 0.3342 - val_accuracy: 0.9205\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3326 - accuracy: 0.9003 - val_loss: 0.3262 - val_accuracy: 0.9195\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3386 - accuracy: 0.8969 - val_loss: 0.3318 - val_accuracy: 0.9198\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.3339 - accuracy: 0.8975 - val_loss: 0.3564 - val_accuracy: 0.9125\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3426 - accuracy: 0.8966 - val_loss: 0.3232 - val_accuracy: 0.9207\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3234 - accuracy: 0.9038 - val_loss: 0.3406 - val_accuracy: 0.9174\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3117 - accuracy: 0.9070 - val_loss: 0.3341 - val_accuracy: 0.9230\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3250 - accuracy: 0.9025 - val_loss: 0.3155 - val_accuracy: 0.9261\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3144 - accuracy: 0.9061 - val_loss: 0.3684 - val_accuracy: 0.9086\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.3253 - accuracy: 0.9011 - val_loss: 0.3384 - val_accuracy: 0.9206\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3133 - accuracy: 0.9063 - val_loss: 0.3283 - val_accuracy: 0.9215\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3164 - accuracy: 0.9037 - val_loss: 0.3230 - val_accuracy: 0.9224\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3179 - accuracy: 0.9061 - val_loss: 0.3037 - val_accuracy: 0.9275\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3122 - accuracy: 0.9055 - val_loss: 0.3177 - val_accuracy: 0.9245\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3096 - accuracy: 0.9069 - val_loss: 0.3089 - val_accuracy: 0.9269\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3029 - accuracy: 0.9090 - val_loss: 0.3195 - val_accuracy: 0.9256\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.3016 - accuracy: 0.9093 - val_loss: 0.3073 - val_accuracy: 0.9263\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3094 - accuracy: 0.9065 - val_loss: 0.3107 - val_accuracy: 0.9287\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3016 - accuracy: 0.9083 - val_loss: 0.3310 - val_accuracy: 0.9199\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.2919 - accuracy: 0.9105 - val_loss: 0.2992 - val_accuracy: 0.9306\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2958 - accuracy: 0.9102 - val_loss: 0.3169 - val_accuracy: 0.9227\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.2942 - accuracy: 0.9108 - val_loss: 0.3152 - val_accuracy: 0.9276\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.3015 - accuracy: 0.9093 - val_loss: 0.3117 - val_accuracy: 0.9251\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2821 - accuracy: 0.9137 - val_loss: 0.3167 - val_accuracy: 0.9233\n",
      "test_score [0.5704085892049803, 0.8617778]\n",
      "Try 9/100: Best_val_acc: [0.5704085892049803, 0.8617778], lr: 0.07559914459296464, Lambda: 4.636865003615338e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "for k in range(1,10):\n",
    "    lr = math.pow(10, np.random.uniform(-5.0, 1.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-7,-2))\n",
    "    model,best_acc = modeldef_train_and_test_loop(100, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and evaluate the model. Print the loss and accuracy for the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose best model try 5 from the above lot as it gives minimim loss and high val accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42000/42000 [==============================] - 2s 39us/sample - loss: 0.2969 - accuracy: 0.9101 - val_loss: 0.3240 - val_accuracy: 0.9252\n",
    "test_score [0.557976202537616, 0.8655]\n",
    "Try 5/100: Best_val_acc: [0.557976202537616, 0.8655], lr: 0.0010950421470782964, Lambda: 6.10775207478701e-06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor the loss visually,\n",
    "####  Plot the training loss, validation loss vs number of epochs and training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.2983 - accuracy: 0.9111 - val_loss: 0.2879 - val_accuracy: 0.9345\n",
      "test_score [0.5584547995560699, 0.8637222]\n"
     ]
    }
   ],
   "source": [
    "# Try 6/100: Best_val_acc: [0.543610353483094, 0.8661111], lr: 5.3018589037369146e-05, Lambda: 0.004780313883968358\n",
    "model, bestscore = modeldef_train_and_test_loop(100, 0.075, 4.636865003615338e-05, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations: from the val_loss and validation accuracy vs number of epochs plot, its visible that the loss curve is slowly going down as and when number of epochs are completed. At the same time accuracy is going up and reaches close to 0.86 which means 86% . We can increase accuracy further by increasing epochs as loss is still going down but it might overfit the model so keeping best model with epoch of 100. Additinally accuracy is not improving much post 100 epochs. So model converges at 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 47us/sample - loss: 0.5585 - accuracy: 0.8637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5584547995560699, 0.8637222]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above is best model so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try changing a few hyperparameters:such as replace Adam to SGD,  number of layers in the network or number of units in a hidden layer or try different activation functions in the hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change optimizer and hidden nodes in dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "        \n",
    "    model = Sequential()\n",
    "    # Normalize the data\n",
    "    model.add(tensorflow.keras.layers.BatchNormalization())\n",
    "    # Hidden layers\n",
    "    model.add(tensorflow.keras.layers.Dense(hidden_nodes, activation='relu', name='Layer_1'))\n",
    "    model.add(tensorflow.keras.layers.Dense(128, activation='relu', name='Layer_2'))\n",
    "\n",
    "    # Dropout layer\n",
    "    model.add(tensorflow.keras.layers.Dropout(0.5))\n",
    "\n",
    "    # Hidden layers\n",
    "    model.add(tensorflow.keras.layers.Dense(64, activation='sigmoid', name='Layer_3'))\n",
    "    model.add(tensorflow.keras.layers.Dense(32, activation='sigmoid', name='Layer_4'))\n",
    "\n",
    "    # Dropout layer\n",
    "    model.add(tensorflow.keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    \n",
    "    score = model.evaluate(X_train, y_train, verbose=0)\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('test_score', test_score)\n",
    "    \n",
    "    return model, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 774\n",
      "Train on 42000 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 2.5080 - accuracy: 0.0992 - val_loss: 2.4966 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.4235 - accuracy: 0.1029 - val_loss: 2.3987 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.3900 - accuracy: 0.1016 - val_loss: 2.3550 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 2.3762 - accuracy: 0.1027 - val_loss: 2.3350 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.3706 - accuracy: 0.1037 - val_loss: 2.3252 - val_accuracy: 1.1905e-04\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3703 - accuracy: 0.1020 - val_loss: 2.3200 - val_accuracy: 7.1429e-04\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.3664 - accuracy: 0.1018 - val_loss: 2.3167 - val_accuracy: 0.0027\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 2.3629 - accuracy: 0.1016 - val_loss: 2.3154 - val_accuracy: 0.0074\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.3634 - accuracy: 0.1003 - val_loss: 2.3151 - val_accuracy: 0.0148\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.3579 - accuracy: 0.1010 - val_loss: 2.3137 - val_accuracy: 0.0246\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.3596 - accuracy: 0.1014 - val_loss: 2.3135 - val_accuracy: 0.0302\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 2.3547 - accuracy: 0.1026 - val_loss: 2.3118 - val_accuracy: 0.0392\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3538 - accuracy: 0.1009 - val_loss: 2.3123 - val_accuracy: 0.0382\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 2.3516 - accuracy: 0.1053 - val_loss: 2.3121 - val_accuracy: 0.0413\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 2s 41us/sample - loss: 2.3481 - accuracy: 0.1062 - val_loss: 2.3111 - val_accuracy: 0.0475\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 2.3508 - accuracy: 0.1028 - val_loss: 2.3102 - val_accuracy: 0.0518\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 2s 37us/sample - loss: 2.3498 - accuracy: 0.1017 - val_loss: 2.3114 - val_accuracy: 0.0476\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 2.3451 - accuracy: 0.1048 - val_loss: 2.3112 - val_accuracy: 0.0507\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 2.3452 - accuracy: 0.1059 - val_loss: 2.3095 - val_accuracy: 0.0580\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 2.3445 - accuracy: 0.1029 - val_loss: 2.3090 - val_accuracy: 0.0606\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 2.3433 - accuracy: 0.1038 - val_loss: 2.3094 - val_accuracy: 0.0588\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 2s 38us/sample - loss: 2.3420 - accuracy: 0.1057 - val_loss: 2.3088 - val_accuracy: 0.0643\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 2.3415 - accuracy: 0.1029 - val_loss: 2.3083 - val_accuracy: 0.0679\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 2s 38us/sample - loss: 2.3409 - accuracy: 0.1052 - val_loss: 2.3077 - val_accuracy: 0.0717\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 2s 36us/sample - loss: 2.3399 - accuracy: 0.1045 - val_loss: 2.3071 - val_accuracy: 0.0770\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 2.3383 - accuracy: 0.1050 - val_loss: 2.3064 - val_accuracy: 0.0806\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 2s 38us/sample - loss: 2.3347 - accuracy: 0.1052 - val_loss: 2.3066 - val_accuracy: 0.0813\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 2s 37us/sample - loss: 2.3361 - accuracy: 0.1050 - val_loss: 2.3061 - val_accuracy: 0.0833\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 2.3343 - accuracy: 0.1051 - val_loss: 2.3060 - val_accuracy: 0.0838\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 2.3326 - accuracy: 0.1061 - val_loss: 2.3056 - val_accuracy: 0.0869\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3319 - accuracy: 0.1064 - val_loss: 2.3051 - val_accuracy: 0.0902\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3326 - accuracy: 0.1086 - val_loss: 2.3050 - val_accuracy: 0.0888\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 2.3318 - accuracy: 0.1052 - val_loss: 2.3040 - val_accuracy: 0.0954\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3279 - accuracy: 0.1089 - val_loss: 2.3027 - val_accuracy: 0.1052\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3284 - accuracy: 0.1059 - val_loss: 2.3021 - val_accuracy: 0.1092\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 2.3270 - accuracy: 0.1116 - val_loss: 2.3026 - val_accuracy: 0.1069\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 2.3287 - accuracy: 0.1098 - val_loss: 2.3026 - val_accuracy: 0.1049\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 2.3247 - accuracy: 0.1067 - val_loss: 2.3024 - val_accuracy: 0.1074\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 2s 37us/sample - loss: 2.3257 - accuracy: 0.1071 - val_loss: 2.3016 - val_accuracy: 0.1143\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3259 - accuracy: 0.1070 - val_loss: 2.3008 - val_accuracy: 0.1190\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3248 - accuracy: 0.1075 - val_loss: 2.3002 - val_accuracy: 0.1240\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 2.3244 - accuracy: 0.1077 - val_loss: 2.2997 - val_accuracy: 0.1296\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3238 - accuracy: 0.1103 - val_loss: 2.2994 - val_accuracy: 0.1323\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3221 - accuracy: 0.1108 - val_loss: 2.2980 - val_accuracy: 0.1462\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3225 - accuracy: 0.1110 - val_loss: 2.2982 - val_accuracy: 0.1437\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3215 - accuracy: 0.1101 - val_loss: 2.2978 - val_accuracy: 0.1467\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 2.3204 - accuracy: 0.1118 - val_loss: 2.2974 - val_accuracy: 0.1499\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 2.3205 - accuracy: 0.1091 - val_loss: 2.2971 - val_accuracy: 0.1531\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3207 - accuracy: 0.1100 - val_loss: 2.2968 - val_accuracy: 0.1543\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 2.3183 - accuracy: 0.1129 - val_loss: 2.2967 - val_accuracy: 0.1556\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 2.3173 - accuracy: 0.1116 - val_loss: 2.2962 - val_accuracy: 0.1617\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 2.3199 - accuracy: 0.1102 - val_loss: 2.2959 - val_accuracy: 0.1654\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 2s 36us/sample - loss: 2.3180 - accuracy: 0.1115 - val_loss: 2.2948 - val_accuracy: 0.1746\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 2.3153 - accuracy: 0.1138 - val_loss: 2.2940 - val_accuracy: 0.1820\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3143 - accuracy: 0.1143 - val_loss: 2.2932 - val_accuracy: 0.1886\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 2.3153 - accuracy: 0.1146 - val_loss: 2.2923 - val_accuracy: 0.1967\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3133 - accuracy: 0.1156 - val_loss: 2.2919 - val_accuracy: 0.2006\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 2.3162 - accuracy: 0.1103 - val_loss: 2.2921 - val_accuracy: 0.1973\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3147 - accuracy: 0.1135 - val_loss: 2.2922 - val_accuracy: 0.1964\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3124 - accuracy: 0.1119 - val_loss: 2.2912 - val_accuracy: 0.2094\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 2s 38us/sample - loss: 2.3118 - accuracy: 0.1147 - val_loss: 2.2910 - val_accuracy: 0.2096\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 2.3127 - accuracy: 0.1121 - val_loss: 2.2913 - val_accuracy: 0.2040\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3111 - accuracy: 0.1136 - val_loss: 2.2909 - val_accuracy: 0.2073\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3102 - accuracy: 0.1132 - val_loss: 2.2901 - val_accuracy: 0.2157\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3085 - accuracy: 0.1166 - val_loss: 2.2890 - val_accuracy: 0.2248\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3121 - accuracy: 0.1158 - val_loss: 2.2887 - val_accuracy: 0.2263\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 2.3115 - accuracy: 0.1139 - val_loss: 2.2883 - val_accuracy: 0.2287\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3091 - accuracy: 0.1160 - val_loss: 2.2878 - val_accuracy: 0.2308\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3076 - accuracy: 0.1204 - val_loss: 2.2873 - val_accuracy: 0.2340\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3084 - accuracy: 0.1183 - val_loss: 2.2870 - val_accuracy: 0.2352\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 2.3076 - accuracy: 0.1175 - val_loss: 2.2866 - val_accuracy: 0.2377\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3044 - accuracy: 0.1204 - val_loss: 2.2857 - val_accuracy: 0.2457\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 3s 68us/sample - loss: 2.3056 - accuracy: 0.1188 - val_loss: 2.2852 - val_accuracy: 0.2496\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 2.3054 - accuracy: 0.1184 - val_loss: 2.2851 - val_accuracy: 0.2480\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 2s 36us/sample - loss: 2.3069 - accuracy: 0.1189 - val_loss: 2.2843 - val_accuracy: 0.2545\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 2s 36us/sample - loss: 2.3035 - accuracy: 0.1197 - val_loss: 2.2837 - val_accuracy: 0.2583\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 2s 37us/sample - loss: 2.3043 - accuracy: 0.1202 - val_loss: 2.2829 - val_accuracy: 0.2643\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 2.3032 - accuracy: 0.1199 - val_loss: 2.2824 - val_accuracy: 0.2652\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 2.3045 - accuracy: 0.1193 - val_loss: 2.2811 - val_accuracy: 0.2789\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3041 - accuracy: 0.1217 - val_loss: 2.2802 - val_accuracy: 0.2850\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 2.3028 - accuracy: 0.1205 - val_loss: 2.2798 - val_accuracy: 0.2840\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 2.3015 - accuracy: 0.1213 - val_loss: 2.2790 - val_accuracy: 0.2874\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 2.3020 - accuracy: 0.1221 - val_loss: 2.2787 - val_accuracy: 0.2864\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.2990 - accuracy: 0.1236 - val_loss: 2.2777 - val_accuracy: 0.2905\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 2.2992 - accuracy: 0.1233 - val_loss: 2.2769 - val_accuracy: 0.2944\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.2988 - accuracy: 0.1241 - val_loss: 2.2764 - val_accuracy: 0.2935\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.2970 - accuracy: 0.1260 - val_loss: 2.2754 - val_accuracy: 0.3008\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 2.2983 - accuracy: 0.1257 - val_loss: 2.2749 - val_accuracy: 0.3024\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 2.2972 - accuracy: 0.1251 - val_loss: 2.2739 - val_accuracy: 0.3069\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.2962 - accuracy: 0.1264 - val_loss: 2.2728 - val_accuracy: 0.3135\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.2954 - accuracy: 0.1289 - val_loss: 2.2716 - val_accuracy: 0.3218\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 2.2947 - accuracy: 0.1295 - val_loss: 2.2705 - val_accuracy: 0.3289\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 2.2951 - accuracy: 0.1294 - val_loss: 2.2699 - val_accuracy: 0.3288\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.2933 - accuracy: 0.1300 - val_loss: 2.2693 - val_accuracy: 0.3290\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.2939 - accuracy: 0.1282 - val_loss: 2.2685 - val_accuracy: 0.3305\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 2.2922 - accuracy: 0.1306 - val_loss: 2.2672 - val_accuracy: 0.3367\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 2s 40us/sample - loss: 2.2925 - accuracy: 0.1311 - val_loss: 2.2661 - val_accuracy: 0.3388\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.2921 - accuracy: 0.1292 - val_loss: 2.2654 - val_accuracy: 0.3383\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.2897 - accuracy: 0.1334 - val_loss: 2.2641 - val_accuracy: 0.3446\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.2890 - accuracy: 0.1330 - val_loss: 2.2630 - val_accuracy: 0.3467\n",
      "test_score [2.267508991241455, 0.2846111]\n"
     ]
    }
   ],
   "source": [
    "model, bestscore = train_and_test_loop(100, 0.001, 4.636865003615338e-04, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 49us/sample - loss: 2.2675 - accuracy: 0.2846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.267508991241455, 0.2846111]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by changing activation functions , accuracy seemed to have reduced. Model is not converging. So original model with hyperparameter tuning done earlier is best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result : Validation accuracy - 92 % and More than 86 % accuracy achieved on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## observations\n",
    "## val vs Test accuracy is 92 /86. Slight variance of 5 to 6% is valid. \n",
    "### Best accuracy is achieved with optimizer: Adam and Learning Rate:  0.075 and\n",
    "lambda = 4.636865003615338e-05\n",
    "### leraning rate Decay - 1E-6\n",
    "### Drop out with probability < 0.5 dropped to reduce overfit in the model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_Python_Neural_Network_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
